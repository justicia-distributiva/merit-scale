},
error = function(x) { NULL }
)
}
#' @importFrom stats deviance
m_deviance <- function(x) {
if (is_merMod(x)) {
if (!requireNamespace("lme4", quietly = TRUE)) {
stop("Package 'lme4' required for this function to work, please install it.")
}
d <- lme4::getME(x, "devcomp")$cmp["dev"]
if (is.na(d)) d <- stats::deviance(x, REML = FALSE)
} else {
d <- stats::deviance(x)
}
d
}
#' @importFrom purrr map as_vector
tidy_label <- function(labs, sep = ".") {
# create table, and check if any value label is duplicated
duped.val <- names(which(table(labs) > 1))
# find position of duplicated labels
dupes <- duped.val %>%
purrr::map(~which(labs == .x)) %>%
purrr::as_vector(.type = "double")
# prefix labels with value
labs[dupes] <- sprintf("%s%s%s", labs[dupes], sep, dupes)
labs
}
#' @importFrom purrr map_df
#' @importFrom insight find_random
se_ranef <- function(object) {
if (!requireNamespace("lme4", quietly = TRUE)) {
stop("Package 'lme4' required for this function to work, please install it.")
}
if (inherits(object, "MixMod")) {
se.bygroup <- lme4::ranef(object, post_vars = TRUE)
vars.m <- attr(se.bygroup, "post_vars")
if (dim(vars.m[[1]])[1] == 1)
se.bygroup <- sqrt(unlist(vars.m))
else {
se.bygroup <- do.call(
rbind,
purrr::map_df(vars.m, ~ t(as.data.frame(sqrt(diag(.x)))))
)
dimnames(se.bygroup)[[2]] <- dimnames(vars.m[[1]])[[1]]
se.bygroup <- list(se.bygroup)
names(se.bygroup) <- insight::find_random(object, flatten = TRUE)
}
} else {
se.bygroup <- lme4::ranef(object, condVar = TRUE)
n.groupings <- length(se.bygroup)
for (m in 1:n.groupings) {
vars.m <- attr(se.bygroup[[m]], "postVar")
K <- dim(vars.m)[1]
J <- dim(vars.m)[3]
names.full <- dimnames(se.bygroup[[m]])
se.bygroup[[m]] <- array(NA, c(J, K))
for (j in 1:J) {
se.bygroup[[m]][j, ] <- sqrt(diag(as.matrix(vars.m[, , j])))
}
dimnames(se.bygroup[[m]]) <- list(names.full[[1]], names.full[[2]])
}
}
se.bygroup
}
#' @importFrom insight n_obs
get_observations <- function(model) {
tryCatch(
{
insight::n_obs(model)
},
error = function(x) { NULL }
)
}
#' @importFrom insight find_predictors get_data
.labelled_model_data <- function(models) {
# to be generic, make sure argument is a list
if (!inherits(models, "list")) models <- list(models)
# get model terms and model frame
mf <- try(lapply(models, function(.x) insight::get_data(.x)[, -1, drop = FALSE]), silent = TRUE)
# return NULL on error
if (inherits(mf, "try-error")) {
return(FALSE)
}
# get all variable labels for predictors
lbs <- unlist(lapply(mf, function(x) {
any(sapply(x, function(i) !is.null(attributes(i)$label)))
}))
any(lbs)
}
# evaluates arguments
get_dot_data <- function(data, dots) {
# any dots?
if (length(dots) > 0)
# get variable names
vars <- dot_names(dots)
else
vars <- NULL
# check if data is a data frame
if (is.data.frame(data)) {
# get valid variable names
vars <- vars[vars %in% colnames(data)]
vars.is.empty <- sjmisc::is_empty(vars)
if (!is.null(vars) && !vars.is.empty)
# select variables, if any
x <- data[, vars, drop = FALSE]
else
# else return complete data frame
x <- data
}
x
}
# return names of objects passed as ellipses argument
dot_names <- function(dots) unname(unlist(lapply(dots, as.character)))
#' @importFrom dplyr quos select
get_dplyr_dot_data <- function(x, qs) {
if (sjmisc::is_empty(qs))
x
else
suppressMessages(dplyr::select(x, !!!qs))
}
# add annotations with table summary
# here we print out total N of cases, chi-square and significance of the table
print.table.summary <- function(baseplot,
modsum,
summary.pos = "r") {
if (!is.null(modsum)) {
# add annotations with table summary
# here we print out total N of cases, chi-square and significance of the table
if (summary.pos == "r") {
t.hjust <- "top"
x.x <- Inf
} else {
t.hjust <- "bottom"
x.x <- -Inf
}
baseplot <- baseplot +
annotate(
"text",
label = modsum,
parse = TRUE,
x = x.x,
y = Inf,
vjust = "top",
hjust = t.hjust
)
}
baseplot
}
get_var_name <- function(x) {
if (is.null(x)) return(NULL)
# remove "data frame name"
dollar_pos <- regexpr("$", x, fixed = T)[1]
if (dollar_pos != -1)
x <- substr(x, start = dollar_pos + 1, stop = nchar(x))
x
}
# Create frequency data frame of a variable
# for sjp and sjt frq functions
#' @importFrom stats na.omit ftable na.pass
#' @importFrom tidyr spread
create.xtab.df <- function(x,
grp,
round.prz = 2,
na.rm = FALSE,
weight.by = NULL) {
# ------------------------------
# convert to labels
# ------------------------------
x_full <- suppressWarnings(sjmisc::to_label(x, add.non.labelled = T))
grp_full <- suppressWarnings(sjmisc::to_label(grp, add.non.labelled = T))
# ------------------------------
# create frequency crosstable. we need to convert
# vector to labelled factor first.
# ------------------------------
if (is.null(weight.by)) {
if (na.rm) {
mydat <- stats::ftable(table(x_full, grp_full))
} else {
mydat <- stats::ftable(table(x_full, grp_full, useNA = "always"))
}
} else {
if (na.rm)
mydat <- stats::ftable(round(stats::xtabs(weight.by ~ x_full + grp_full)), 0)
else
mydat <- stats::ftable(round(stats::xtabs(weight.by ~ x_full + grp_full,
exclude = NULL,
na.action = stats::na.pass)), 0)
}
# create proportional tables, cell values
ori.cell.values <- 100 * prop.table(mydat)
proptab.cell <- round(100 * prop.table(mydat), round.prz)
# create proportional tables, row percentages, including total row
proptab.row <- rbind(
as.data.frame(as.matrix(round(100 * prop.table(mydat, 1), round.prz))),
round(colSums(ori.cell.values), round.prz)
)
rownames(proptab.row)[nrow(proptab.row)] <- "total"
proptab.row <- as.data.frame(apply(proptab.row, c(1, 2), function(x) if (is.na(x)) x <- 0 else x))
# create proportional tables, column  percentages, including total row
proptab.col <- cbind(
as.data.frame(as.matrix(round(100 * prop.table(mydat, 2), round.prz))),
round(rowSums(ori.cell.values), round.prz)
)
colnames(proptab.col)[ncol(proptab.col)] <- "total"
proptab.col <- as.data.frame(apply(proptab.col, c(1, 2), function(x) if (is.na(x)) x <- 0 else x))
# add total row and column to cell percentages afterwards
proptab.cell <- rbind(
as.data.frame(as.matrix(proptab.cell)),
round(colSums(ori.cell.values), round.prz)
)
proptab.cell <- cbind(
as.data.frame(as.matrix(proptab.cell)),
rowSums(proptab.cell)
)
# due to roundings, total might differ from 100%, so clean this here
proptab.cell[nrow(proptab.cell), ncol(proptab.cell)] <- 100
colnames(proptab.cell)[ncol(proptab.cell)] <- "total"
rownames(proptab.cell)[nrow(proptab.cell)] <- "total"
# convert to data frame
mydat <- data.frame(mydat)
colnames(mydat)[2] <- "Var2"
# spread variables back, so we have a table again
mydat <- tidyr::spread(mydat, .data$Var2, .data$Freq)
# rename column names
colnames(mydat)[1] <- "label"
colnames(mydat)[is.na(colnames(mydat))] <- "NA"
colnames(mydat)[colnames(mydat) == "<NA>"] <- "NA"
# label must be character
mydat$label <- as.character(mydat$label)
mydat$label[is.na(mydat$label)] <- "NA"
# save labels to extra vector
labels.cnt <- mydat$label
labels.grp <- colnames(mydat)[-1]
# return result
invisible(structure(list(mydat = mydat,
proptab.cell = proptab.cell,
proptab.col = proptab.col,
proptab.row = proptab.row,
labels.cnt = labels.cnt,
labels.grp = labels.grp)))
}
# check character encoding for HTML-tables
# (sjt-functions)
get.encoding <- function(encoding, data = NULL) {
if (is.null(encoding)) {
if (!is.null(data) && is.data.frame(data)) {
# get variable label
labs <- sjlabelled::get_label(data[[1]])
# check if vectors of data frame have
# any valid label. else, default to utf-8
if (!is.null(labs) && is.character(labs))
encoding <- Encoding(sjlabelled::get_label(data[[1]]))
else
encoding <- "UTF-8"
# unknown encoding? default to utf-8
if (encoding == "unknown") encoding <- "UTF-8"
} else if (.Platform$OS.type == "unix")
encoding <- "UTF-8"
else
encoding <- "Windows-1252"
}
return(encoding)
}
# Calculate statistics of cross tabs
#' @importFrom sjstats cramer phi table_values
#' @importFrom stats chisq.test fisher.test xtabs
crosstabsum <- function(x, grp, weight.by) {
# --------------------------------------------------------
# check p-value-style option
# --------------------------------------------------------
opt <- getOption("p_zero")
if (is.null(opt) || opt == FALSE) {
p_zero <- ""
} else {
p_zero <- "0"
}
if (is.null(weight.by)) {
ftab <- table(x, grp)
} else {
ftab <- round(stats::xtabs(weight.by ~ x + grp), 0)
}
# calculate chi square value
chsq <- stats::chisq.test(ftab)
p.value <- chsq$p.value
tab <- sjstats::table_values(ftab)
# do we have cells with less than 5 observations?
if (min(tab$expected) < 5 || (min(tab$expected) < 10 && chsq$parameter == 1)) {
fish <- stats::fisher.test(ftab, simulate.p.value = (nrow(ftab) > 2 || ncol(ftab) > 2))
p.value <- fish$p.value
} else {
fish <- NULL
}
# pvalue in string
if (p.value < 0.001)
pvas <- sprintf("%s.001", p_zero)
else
pvas <- sub("0", p_zero, sprintf("%.3f", p.value))
# check whether variables are dichotome or if they have more
# than two categories. if they have more, use Cramer's V to calculate
# the contingency coefficient
if (nrow(ftab) > 2 || ncol(ftab) > 2) {
# check whether fisher's test or chi-squared should be printed
if (is.null(fish)) {
modsum <- as.character(as.expression(
substitute("N" == tn * "," ~~ chi^2 == c2 * "," ~~ "df" == dft * "," ~~ phi[c] == kook * "," ~~ "p" == pva,
list(tn = summary(ftab)$n.cases,
c2 = sprintf("%.2f", chsq$statistic),
dft = c(chsq$parameter),
kook = sprintf("%.2f", sjstats::cramer(ftab)),
pva = pvas))))
} else {
modsum <- as.character(as.expression(
substitute("N" == tn * "," ~~ "df" == dft * "," ~~ phi[c] == kook * "," ~~ "Fisher's p" == pva,
list(tn = summary(ftab)$n.cases,
dft = c(chsq$parameter),
kook = sprintf("%.2f", sjstats::cramer(ftab)),
pva = pvas))))
}
# if variables have two categories (2x2 table), use phi to calculate
# the degree of association
} else {
# check whether fisher's test or chi-squared should be printed
if (is.null(fish)) {
modsum <- as.character(as.expression(
substitute("N" == tn * "," ~~ chi^2 == c2 * "," ~~ "df" == dft * "," ~~ phi == kook * "," ~~ "p" == pva,
list(tn = summary(ftab)$n.cases,
c2 = sprintf("%.2f", chsq$statistic),
dft = c(chsq$parameter),
kook = sprintf("%.2f", sjstats::phi(ftab)),
pva = pvas))))
} else {
modsum <- as.character(as.expression(
substitute("N" == tn * "," ~~ "df" == dft * "," ~~ phi == kook * "," ~~ "Fisher's p" == pva,
list(tn = summary(ftab)$n.cases,
dft = c(chsq$parameter),
kook = sprintf("%.2f", sjstats::phi(ftab)),
pva = pvas))))
}
}
return(modsum)
}
# Erzeugt eine rotierte Faktorladungen einer Hauptkomponentenanalyse
# (Paramter "data") mit einer bestimmten Anzahl an Faktoren (Parameter "factors")
# auf Grundlage der Varimax-Rotation
#
# Parameter:
# - data: the results (object) from a principal component analysis
#         (prcomp(myData...))
# - factors: the amount of factors. can be calculated from the
#            below function "factorcount"
#' @importFrom stats varimax
varimaxrota <- function(data, factors) {
# Faktorladungen berechnen
# Die Faktorladungen erh채lt man durch Multiplikation der Eigenvektoren
# mit der Diagonalmatrix der ausgewiesenen Standardabweichungen
ladungen <- data$rotation %*% diag(data$sdev)
# Zur Durchf체hrung der VARIMAX-Rotation erzeugen wir eine Matrix
# mit den Faktorladungen der ausgew채hlten Faktoren (Anzahl = Parameter "factors")
# Varimax Rotation durchf체hren
varib <- stats::varimax(ladungen[, seq_len(factors)])
varib
}
# unlist labels
# Help function that unlists a list into a vector
unlistlabels <- function(lab) {
dummy <- unlist(lab)
labels <- c()
labels <- c(labels, as.character(dummy))
return(labels)
}
sju.rmspc <- function(html.table) {
cleaned <- gsub("      <", "<", html.table, fixed = TRUE, useBytes = TRUE)
cleaned <- gsub("    <", "<", cleaned, fixed = TRUE, useBytes = TRUE)
cleaned <- gsub("  <", "<", cleaned, fixed = TRUE, useBytes = TRUE)
return(cleaned)
}
.is_false <- function(x) {
is.logical(x) && length(x) == 1L && !is.na(x) && !x
}
# before you run this line, check if your R Markdown files have a .rmd or .Rmd extension
# on this case we use both
ext <- c(grep("^prod_.*\\.rmd$",x = dir(path = "docs"),value = T), # for .rmd
grep("^prod_.*\\.Rmd$",x = dir(path = "docs"),value = T), # for .Rmd
".tex",".log")                                            # for .tex and .log
for (i in 1:length(ext)) {
file.remove(paste0("docs/",dir(path="docs", pattern=ext[i]))) # delete files
}
# before you run this line, check if your R Markdown files have a .rmd or .Rmd extension
# on this case we use both
ext <- c(grep("^prod_.*\\.rmd$",x = dir(path = "docs"),value = T), # for .rmd
grep("^prod_.*\\.Rmd$",x = dir(path = "docs"),value = T), # for .Rmd
".tex",".log")                                            # for .tex and .log
for (i in 1:length(ext)) {
file.remove(paste0("docs/",dir(path="docs", pattern=ext[i]))) # delete files
}
production<- list.files(path = "production",pattern = "prod_")        # a list with the names of the files to copy
file.copy(file.path("production",production), "docs",overwrite = TRUE)# copy data proc and analysis files
rmarkdown::render_site("docs") # Render site
print(dfSummary(dat04, valid.col = FALSE, graph.magnif = 0.75),
max.tbl.height = 300, method = "render")
# before you run this line, check if your R Markdown files have a .rmd or .Rmd extension
# on this case we use both
ext <- c(grep("^prod_.*\\.rmd$",x = dir(path = "docs"),value = T), # for .rmd
grep("^prod_.*\\.Rmd$",x = dir(path = "docs"),value = T), # for .Rmd
".tex",".log")                                            # for .tex and .log
for (i in 1:length(ext)) {
file.remove(paste0("docs/",dir(path="docs", pattern=ext[i]))) # delete files
}
production<- list.files(path = "production",pattern = "prod_")        # a list with the names of the files to copy
file.copy(file.path("production",production), "docs",overwrite = TRUE)# copy data proc and analysis files
rmarkdown::render_site("docs") # Render site
# before you run this line, check if your R Markdown files have a .rmd or .Rmd extension
# on this case we use both
ext <- c(grep("^prod_.*\\.rmd$",x = dir(path = "docs"),value = T), # for .rmd
grep("^prod_.*\\.Rmd$",x = dir(path = "docs"),value = T), # for .Rmd
".tex",".log")                                            # for .tex and .log
for (i in 1:length(ext)) {
file.remove(paste0("docs/",dir(path="docs", pattern=ext[i]))) # delete files
}
production<- list.files(path = "production",pattern = "prod_")        # a list with the names of the files to copy
file.copy(file.path("production",production), "docs",overwrite = TRUE)# copy data proc and analysis files
rmarkdown::render_site("docs") # Render site
w01 <- sjlabelled::read_spss("input/data/original/Estudio_3_ola1.sav",verbose = F)
dat04 <- w01 %>% filter(Intro==1) %>%
select(starts_with("meritv01"),
starts_with("meritv02"),
starts_with("meritv03_p"),
starts_with("FL_21_DO"))
dat04$grupo <- NA
dat04$grupo[dat04$FL_21_DO_merit_perc_pref_julio19v01==1] <- 1
dat04$grupo[dat04$FL_21_DO_merit_perc_pref_julio19v02==1] <- 2
dat04$grupo[dat04$FL_21_DO_merit_perc_pref_julio19v03==1] <- 3
dat04$perc_effort <- rowSums(dat04[,c(matches(match = "perc_effort",vars = names(dat04)))],na.rm = TRUE)
dat04$perc_talent <- rowSums(dat04[,c(matches(match = "perc_talent",vars = names(dat04)))],na.rm = TRUE)
dat04$perc_wpart  <- rowSums(dat04[,c(matches(match = "perc_wpart" ,vars = names(dat04)))],na.rm = TRUE)
dat04$perc_netw   <- rowSums(dat04[,c(matches(match = "perc_netw"  ,vars = names(dat04)))],na.rm = TRUE)
dat04$pref_effort <- rowSums(dat04[,c(matches(match = "pref_effort",vars = names(dat04)))],na.rm = TRUE)
dat04$pref_talent <- rowSums(dat04[,c(matches(match = "pref_talent",vars = names(dat04)))],na.rm = TRUE)
dat04$pref_wpart  <- rowSums(dat04[,c(matches(match = "pref_wpart" ,vars = names(dat04)))],na.rm = TRUE)
dat04$pref_netw   <- rowSums(dat04[,c(matches(match = "pref_netw"  ,vars = names(dat04)))],na.rm = TRUE)
dat04[dat04==0] <- NA
dat04 <- dat04 %>% select(starts_with(match = "perc_"),starts_with(match = "pref_"),grupo) %>% na.omit()
label(dat04$grupo) <- "This variable classifies the interviewees according to the order in which the indicators are shown within the scale. There are three orders  of items on the scale. In the first order (group 1), questions of the same factor are then presented to them, in the second order (group 2) they were separated and in the third order (group 3) at random."
dat04$perc_effort <- set_labels(dat04$perc_effort,  labels = c("strongly disagree" = 1, "disagreement" = 2, "Neither agree nor disagree"=3,"Agree"=4, "totally agree" = 5))
label(dat04$perc_effort) <- "Thinking of Chilean society,
what measure do you find of
agree or disagree with each of
the following statements? - Who
the more they try they manage to get bigger
rewards that those who strive
less."
dat04$perc_talent <- set_labels(dat04$perc_talent,  labels = c("strongly disagree" = 1, "disagreement" = 2, "Neither agree nor disagree"=3,"Agree"=4, "totally agree" = 5))
label(dat04$perc_talent) <- "Thinking of Chilean society,
what measure do you find of
agree or disagree with each of
the following statements? - Who
possess more talent they manage to obtain
greater rewards than those who possess
less talent."
dat04$perc_wpart <- set_labels(dat04$perc_wpart,  labels = c("strongly disagree" = 1, "disagreement" = 2, "Neither agree nor disagree"=3,"Agree"=4, "totally agree" = 5))
label(dat04$perc_wpart) <- "Thinking of Chilean society,
what measure do you find of
agree or disagree with each of
the following statements? - Who
they have rich parents manage to get out
ahead."
dat04$perc_netw <- set_labels(dat04$perc_netw,  labels = c("strongly disagree" = 1, "disagreement" = 2, "Neither agree nor disagree"=3,"Agree"=4, "totally agree" = 5))
label(dat04$perc_netw) <- "Thinking of Chilean society,
what measure do you find of
agree or disagree with each of
the following statements? - Who
they have good contacts they manage to get out
ahead."
dat04$pref_effort <- set_labels(dat04$pref_effort,  labels = c("strongly disagree" = 1, "disagreement" = 2, "Neither agree nor disagree"=3,"Agree"=4, "totally agree" = 5))
label(dat04$pref_effort) <- "Thinking of Chilean society,
what measure do you find of
agree or disagree with each of
the following statements? - Who
the more they try they should get
greater rewards than those who
they try less."
dat04$pref_talent <- set_labels(dat04$pref_talent,  labels = c("strongly disagree" = 1, "disagreement" = 2, "Neither agree nor disagree"=3,"Agree"=4, "totally agree" = 5))
label(dat04$pref_talent) <- "Thinking of Chilean society,
what measure do you find of
agree or disagree with each of
the following statements? - Who
possess more talent they should get
greater rewards than those who possess
less talent."
dat04$pref_wpart <- set_labels(dat04$pref_wpart,  labels = c("strongly disagree" = 1, "disagreement" = 2, "Neither agree nor disagree"=3,"Agree"=4, "totally agree" = 5))
label(dat04$pref_wpart) <- "Thinking of Chilean society,
what measure do you find of
agree or disagree with each of
the following statements? - Is
well that those who have good
contacts get ahead."
dat04$pref_netw <- set_labels(dat04$pref_netw,  labels = c("strongly disagree", "disagreement", "Neither agree nor disagree","Agree", "totally agree"))
label(dat04$pref_netw) <- "Thinking of Chilean society,
what measure do you find of
agree or disagree with each of
the following statements? - Is
well that those who have good
contacts get ahead."
dat04 <-  dat04 %>% select(grupo, perc_effort, perc_talent, perc_wpart, perc_netw, pref_effort, pref_talent, pref_wpart , pref_netw) %>% as.data.frame()
print(dfSummary(dat04, valid.col = FALSE, graph.magnif = 0.75), max.tbl.height = 300, method = "render")
print(dfSummary(dat04, valid.col = FALSE, graph.magnif = 0.75), max.tbl.height = 300, method = "render")
dat01 <- dat04 %>% filter(grupo==1) %>% select(-grupo) %>%  na.omit()
rmarkdown::render("docs/prod_prep-data-A.rmd")
rmarkdown::render("docs/prod_prep-data-A.rmd")
rmarkdown::render_site("docs")
