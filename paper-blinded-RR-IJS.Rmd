---
title: "A multidimensional approach for measuring meritocratic beliefs: Advantages, limitations and alternatives to the ISSP social inequality survey"
#css: "custom.css"
linestretch: '1.5'
link-citations: yes
# author: 
# - name: Juan Carlos Castillo
#   affiliation: Department of Sociology, Universidad de Chile
#   email: juancastillov@uchile.cl
#   number: 1
# - name: Julio Iturra
#   affiliation: Bremen International Graduate School of Social Sciences, Universität Bremen
#   number: 2
# - name: Luis Maldonado
#   affiliation: Institute of Sociology, Universidad Católica de Chile
#   number: 3
# - name: Francisco Meneses
#   affiliation: 
#   number: 1
# - name: Jorge Atria
#   affiliation: Department of Sociology, Universidad Diego Portales, Chile
#   number: 5
abstract: |
  A great part of the comparative international research that has attempted to measure meritocratic beliefs has used the social inequality module of the ISSP (International Social Survey Programme), which offers an unprecedented opportunity to compare meritocratic views in different societies.  Based on a series of studies using ISSP data, the present paper proposes a multidimensional measurement framework for meritocratic beliefs. This framework distinguishes, on the one side, between perceptions and preferences, and on the other side, between meritocratic and not meritocratic aspects. In a first study, we test the multidimensional framework for meritocratic beliefs using the ISSP 2009 inequality module through confirmatory factor analysis (CFA) techniques. After identifying the advantages and some limitations of ISSP items for a multidimensional operationalization of meritocratic beliefs, in a second study, we suggest an modified  set of items that better taps the different dimensions of meritocracy. We examined the measuring properties of this new instrument using a sample of Chilean adults (N=2,141). Based on these results, we recommend improvements in measuring meritocratic beliefs in cross-national studies.
  \newline
  \newline
  
   **Keywords**: meritocracy, survey methodology, social inequality, construct measurement 
# keywords: "meritocracy, survey methodology, social inequality, construct measurement"
output:
  bookdown::word_document2:
    number_sections: false
    reference_docx: input/template.docx
    toc: false
  bookdown::pdf_document2:
    template: null
    number_sections: false    
    toc: false
    keep_tex: true
    pandoc_args:
     - --template=input/mytemplate.tex #custom template para usar autores con afiliacion
  bookdown::html_document2:
    number_sections: false
linkcolor: blue
bibliography: input/bib/meritocracy.bib
csl: input/bib/apa7-singlespace.csl
editor_options:
  chunk_output_type: console
geometry: margin=1in
header-includes:
  - \usepackage{times}           # Times New Roman
#  - \hypersetup {colorlinks = true, linkcolor = blue, urlcolor = blue}    
  - \usepackage{caption}
  - \captionsetup[figure, table]{labelfont={bf},labelformat={default},labelsep=period}
  - \usepackage{graphicx}
  - \usepackage{float}
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{wrapfig}
  - \usepackage{float}
  - \usepackage{colortbl}
  - \usepackage{pdflscape}
  - \usepackage{tabu}
  - \usepackage{threeparttable}
  - \usepackage[british,UKenglish,USenglish,american]{babel}
always_allow_html: true # for word output
fontsize: 10pt
papersize: a4
---

```{r eval=FALSE, include=FALSE}
 # for render in pdf run rmarkdown::render_site("docs/paper.Rmd", output_format = "all")
 # clean #in the yml
 rmarkdown::render("paper-blinded-RR-IJS.Rmd", output_format = "bookdown::pdf_document2")
 rmarkdown::render("paper-blinded-RR-IJS.Rmd", output_format = "bookdown::html_document2")
 rmarkdown::render("paper-blinded-RR-IJS.Rmd", output_format = "bookdown::word_document2")
```

```{r setup, include=FALSE}
 knitr::opts_chunk$set(echo=FALSE, warning = FALSE,message = FALSE, cache = FALSE,out.width = '85%',fig.pos= "H", fig.align = 'center')
 # knitr::opts_knit$set(base.url = "../") #relative path for .html output file
 # knitr::opts_knit$set(root.dir = "../") #relative path for chunks within .rmd files
 options(scipen=999)
 options(kableExtra.auto_format = FALSE)
 rm(list=ls())
 options(knitr.kable.NA = '')
 options(knitr.graphics.error = FALSE)
 Sys.setlocale("LC_ALL", "ES_ES.UTF-8")
```

<!---
\pagebreak

# Acknowledgments

The authors recognize the support of ANID/FONDECYT grant 1160921 and of  the Center for Conflict and Social Cohesion Studies (COES)  grant ANID/FONDAP 1513009.

\pagebreak
\selectlanguage{USenglish} 
--->



# Introduction

Economic inequality and income concentration have become topics of growing concern over the last years, leading to a series of social upheavals in different societies as well as diverse critical analyses regarding the development of capitalism and its consequences [@streeck_politics_2014; @piketty_capital_2014].  In such a context, the study of views, preferences, and perceptions of inequality has acquired relevance in the social sciences, in topics such as redistributive preferences [@alesina_fairness_2005; @dimick_models_2018], the legitimization of economic inequality [@schroder_income_2017] and the functioning of meritocracy [@duru-bellat_who_2012; @mijs_paradox_2019; @reynolds_perceptions_2014; @atria_economic_2020]. Within this research area, and particularly in times of economic and health crises, the ideal of meritocracy has been strongly challenged as an unfulfilled promise of modern societies that allows the perpetuation of social inequalities [@sandel_tyranny_2020; @goldthorpe_myth_2003].

In general, meritocracy has been defined as a system of distribution of resources and rewards based on individual merit, which in its original conception is a combination of talent and effort [@young_rise_1962]. This traditional conception of merit places in a secondary position the possible interference of structural or non-meritocratic factors, such as inheritance, personal contacts, and luck [@breen_class_1999; @saunders_might_1995; @yair_meritocracy_2007; @land_we_2006; @young_rise_1962]. Social psychology and sociology have studied the characteristics and consequences of beliefs in meritocracy, under the general hypothesis that a greater belief in meritocracy emphasizes the role of the individual over structural factors in personal achievements, leading to greater legitimization of inequalities [@preminger_meritocracy_2020; @trump_when_2020; @hadjar_meritokratie_2008; @madeira_primes_2019]. Such research has raised criticism of meritocracy as a moral standard of distribution given the preponderant weight of non-meritocratic elements upon the individual status and social mobility [@sandel_tyranny_2020; @witteveen_reconsidering_2020; @arrow_meritocracy_2000; @goldthorpe_myth_2003; @markovits_meritocracy_2019; @khan_privilege_2013].

Due to the role that meritocratic beliefs play in the justification of individual achievement (or failure) in contemporary societies [@hadjar_meritokratie_2008; @markovits_meritocracy_2019; @sandel_tyranny_2020], multiple studies have evaluated the relationship between meritocratic beliefs and personal and (or) contextual characteristics. For example, some studies have linked meritocracy to the reinforcement of socio-economic, gender, and ethnic stereotypes [@madeira_primes_2019; @girerd_neoliberalism_2020; @girerd_neoliberalism_2020], as well as the effects of meritocratic beliefs in educational [@generett_stories_2020; @owens_engines_2020] and organizational contexts [@perez_advancing_2020; @aiello_new_2019]. Most of such studies so far have used indicators from existing standard social surveys, such as the International Social Survey Programme (ISSP), to measure meritocracy. However, as we will show later, the concepts and instruments used for measuring meritocracy vary extensively among studies. In many cases, similar phenomena are associated with different indicators, and conversely, different phenomena are measured with similar indicators. Such approaches limit the comparability of studies and the capacity to understand the effects of meritocratic beliefs across different disciplines and lines of research, raising doubts about the validity of the instruments used to measure meritocratic beliefs. In this sense, this paper is aligned with recent discussions about the estimand [@lundberg_what_2021] in sociology, this is, the need for a clear definition of what we are estimating as well as the connection of this definition with statistical evidence.

Based on a critical analysis of different approaches to the empirical study of meritocracy to date —most of them using data from the inequality module of ISSP—, this article identifies several conceptual and measurement issues. In order to address them, firstly, we propose a multidimensional conceptual framework for measuring meritocratic beliefs. The proposal consists in a first basic distinction between the dimensions of perceptions and preferences for meritocracy, often confused in the literature. Furthermore, the proposal distinguishes between meritocratic and non-meritocratic dimensions, as they would not be two poles of the same continuum as previous studies suggest. Secondly, we test the validity of our conceptual framework with two studies. Study 1 offers an operationalization and confirmatory analysis of the proposed multidimensional framework using available items from ISSP, inequality module 2009 (the reason to use this survey wave instead of the last one on social inequality from 2019 is that the 2009 version includes some key items used in meritocratic reserach that were removed in 2019). Taking into account on the advantages and limitations of the results obtained in study 1, and in order to gain additional evidence for the validity of the measurement instruments, study 2 suggests modifications and expansion of the items commonly used to measure meritocratic beliefs. This measurement proposal is tested with data available from a Chilean survey on meritocracy and inequality (2020). 

## The black box of meritocratic beliefs {-#blackbox}

In the following, we discuss four critical aspects in studies conceptualizing and measuring meritocracy, based upon which we develop a conceptual and measurement proposal.

a. _Conceptual components_: Is merit only effort?

One recent definition of meritocracy by @mijs_paradox_2019 is the following: "When I discuss meritocracy beliefs, I am referring to citizens' belief in the importance of hard work relative to structural factors." [@mijs_paradox_2019, pg.9]. In the subsequent operationalization, this is associated with the following question and indicator: "how important you think it is for getting ahead in life: (a) hard work", scored on a likert scale. The assumptions behind such a definition are worth discussing in light of the conceptual meaning of meritocracy and its possibilities of operationalization.

The item used by @mijs_paradox_2019 is part of an item's battery which is available in several international surveys (as ISSP), usually called “reasons to get ahead”. In the ISSP, this battery belongs to the social inequality module---see @roberts_issp_2023 for a recent overview of this module. This battery displays a series of indicators related to what people consider important to get ahead: hard work, education, ambition, a wealthy family, the right connections, religion, race, and gender. Therefore, considering only one of the items means that other aspects associated with talent, such as education, would not be deemed meritocratic. As he points out: "Hard work is arguably the most meritocratic part of Michael Young's equation: 'Merit = Intelligence + Effort', for the simple fact that intelligence itself is influenced by a non-meritocratic factor: who your parents happen to be" (p.5). In such conceptual and measurement approach of meritocratic beliefs, we can observe a couple of strong conceptual assumptions: a) effort would not depend on parental influence (at least not as strongly as intelligence), and b) talent (as innate ability) is not meritocratic (contrary to Michael Young's' original conceptualization). This conceptual and measurement-based assumption is found in other studies, which also assume effort to be the main and only aspect of meritocracy [@girerd_neoliberalism_2020; @bubak_perceptions_2019], raising the question: Is effort the only (or main) dimension behind the concept of meritocracy?

We argue that whether talent (as intelligence and ability) is or is not considered meritocratic is an interesting topic to discuss from a philosophical point of view. However, when it comes to survey research on meritocratic beliefs, the weight of effort or talent in what it is deemed  meritocratic should be left to public scrutiny. Furthermore, considering talent as part of meritocracy certainly opens some appealing avenues of research. For instance, some studies suggest that, for the elites, meritocracy is related to talent, whereas effort is more characteristic of the meritocracy of the middle and lower classes [@atria_economic_2020]. Therefore, we suggest that a concept (and measure) of meritocracy benefits from including both talent and effort, as in Young's original conception.

b. _Beliefs?_

Several approaches to the empirical study of meritocracy based on public opinion surveys refer to the concept of _beliefs_, but with wide differences in meanings and operationalizations. To illustrate this point, let us consider the commonly used "reasons to get ahead" items’ battery, mentioned above. Some versions of this battery ask "how important you think it is for getting ahead in life" and then list various factors, whereas another version of this same battery - sometimes presented along the previous one - asks about "how important you think it _should_ be ...", and then listing the same concepts.  Therefore, the question raised here is: Which one of both is a "belief": what _is_ (the first one) or what it _should_ be (the second one)?

The term belief has an ambiguous character in the literature, conceived as "idea-elements" by @converse_nature_1964 or "considerations" by @zaller_nature_1992. As @kluegel_beliefs_1986 pointed out about the scope of beliefs: "This usage encompasses such more specific social-psychological concepts as values, perceptions, and attitudes" (p.30). Therefore, the term _beliefs_ used to cover almost anything related to subjective factors. In this regard, a relevant distinction in the field of inequality beliefs was made by @janmaat_subjective_2013: "Perceptions refer to subjective estimates of existing inequality (i.e., thoughts about what is). Beliefs are here defined as normative ideas about just inequality (i.e., thoughts about what should be)"(p.359). Several papers dealing with meritocracy use the term beliefs (i.e. what should be), while referring to perceptions (i.e., what is). For instance,  in @reynolds_perceptions_2014, the term belief is used to talk about what @janmaat_subjective_2013 refers to as perceptions, whereas other authors use general terms such as attitudes [@kunovich_systems_2007]. The first attempt to shed light on this issue in meritocracy research was made by @duru-bellat_who_2012, who used the question "how important should the number of years spent in education and training be in deciding how much money people ought to earn?" as a proxy for "desired" meritocracy (normative beliefs). They then determined "perceived" meritocracy, using the questions: "Would you say that in your country, people are rewarded for their efforts?" and "... people are rewarded for their skills?".

Is the belief in meritocracy a perception or a preference with normative meaning? To expand the analytical conceptual framework, we believe that both dimensions should be considered, as proposed by @duru-bellat_who_2012. Such an approach opens up the possibility of analyzing whether perceptions and preferences are related (i.e., have a high correlation), or constitute independent aspects of the same phenomenon. As @sonhing_merit_2011 has pointed out, "People can believe that outcomes ought to be distributed based on merit and yet vary in their perceptions of whether this is how society currently operates" (p. 435). In other words, normative beliefs should be considered while taking perceptions into account: a strong normative belief in meritocracy may mean something different to someone perceiving high meritocracy than to someone perceiving low meritocracy. To avoid the confusion generated by the term "belief", we propose the terms meritocratic preferences ("what should be"), and meritocratic perceptions ("what is"), as they better reflect the two facets of meritocracy under scrutiny [@castillo_meritocracia_2019].

c. _Non-meritocratic aspects_

Some research in meritocracy considers aspects usually opposed to effort and talent for personal achievement, for instance, family status and the use of personal advantages (such as contacts or having a wealthy family) to get ahead in life. This distinction refers to the classical achieved and ascribed status dimension from @linton_study_1936.  For instance, @kunovich_systems_2007 used an items' battery following the question “How important each should be in deciding pay..." (as @duru-bellat_who_2012 for desired meritocracy). They consider factors such as education and responsibility as meritocratic, giving them a value of 1 is considered "essential" in the scale response, whereas factors such as having a family or children are valued as 1 when rated as "not important at all" (i.e. reverse coded). The assumption behind this approach is that rejecting a supposed ascribed or non-meritocratic aspect (such as having family and/or children) implies a stronger belief in meritocracy. A similar approach of reverse-coding non-meritocratic items was taken by @newman_false_2015, using the same principles applied in the "Preference for the Merit Principle Scale" [@davey_preference_1999]. 

The assumption that meritocratic and non-meritocratic elements are poles of the same continuum was tested by @reynolds_perceptions_2014 using the "get ahead" perceptions' battery items mentioned above. They considered education, ambition, and hard work as meritocratic, whereas factors such as family wealth and connections were classified as non-meritocratic. Despite making this distinction, in the operationalization the authors end up subtracting one dimension from the other, thus coming back to the assumption that they are two poles of the same continuum, as @kunovich_systems_2007 also did. Similarly, @roex_attitudes_2018 used ISSP indicators for perceived meritocracy and non-meritocracy to build a single score by reverse coding the non-meritocratic items. Therefore, the treatment of non-meritocratic items has been rather inconsistent across studies and the assumption that they are the simple opposite of meritocracy certainly requires further conceptual elaboration and empirical assessment. For instance, a such distinction could open the door to studying to what extent different and contradictory views of meritocracy can coexist, to what extent individuals and societies differ in this regard, and of course the associated factors to such differences. Although the use of the concept "non-meritocratic" is very broad, we prefer to use it instead of other terms like ascription, given that this last one leaves out aspects such as the use of personal relationships as a way to achieve success.

d. _Accounting for measurement error_

Finally, most meritocracy studies have not adequately considered the issue of latent structures and measurement error [@brown_confirmatory_2015; @bollen_structural_1989; @ansolabehere_strength_2008], as they mostly use single indicators and/or simple average indexes for measuring meritocracy. Such a strategy assumes that the latent construct is measured perfectly (i.e., no error or residual variance) by the selected indicators, going as far as to propose that "... In choosing this strategy of index construction, we argue that support for meritocracy is not a latent variable" [@kunovich_systems_2007 p.653-654]. Although Reynolds and Xian [-@reynolds_perceptions_2014] made advances by conducting a principal component analysis of meritocratic and non-meritocratic dimensions, they finally decided to build a sum index despite proving a multidimensional latent structure.

There is a relevant trade-off regarding measurement error estimation in survey instruments. Including multiple items per conceptual dimension opens the possibility of validity studies (at least in terms of the construct) by using factor analysis techniques, particularly confirmatory ones. However, increasing the number of items reduces the probability of usability of the scale in survey research given space limitations. This validity-usability conundrum is not easy to solve and, as we will show later in the methods section, we opted for a minimalistic approach . Such approach is oriented to the usability of the measurement instrument, but still giving the possibility of confirmatory factor analysis.

## A conceptual proposal for studying meritocracy {-#instrumentprop}

Based on the previous assumptions and limitations identified in the empirical study of meritocracy, mostly using the inequality module of ISSP, we propose a measurement framework for the study of meritocratic beliefs with the following characteristics:

- _Multidimensionality_, incorporating previous distinctions between preferences and perceptions, as well as between meritocratic and non-meritocratic aspects.

- Multiple indicators for each dimension to _account for measurement error_ in a confirmatory factor analysis context.

- Based on _previous indicators_ as much as possible to keep comparability between studies. As most of the survey research on meritocracy so far has been made with the inequality module of the ISSP survey, we propose a comprehensive operationalization suitable for this dataset, as well as a novel instrument that attempts to rescue as much as possible the original ISSP items.

- _Brief_, as to be used in regular public opinion surveys [@davidov_measurement_2009]. In this regard, it differs from the proposal of  "Preference for the Merit Principle Scale" [@davey_preference_1999], as they use 15 items for just one dimension (aside from the problem of reverse-coding non-meritocratic items).

The proposed conceptual and measurement framework is depicted in Figure \@ref(fig:merit-model):

```{r merit-model, echo=FALSE, fig.cap = "Conceptual Model of perception and preferences for meritocracy and non-meritocracy", fig.align='center'}
 knitr::include_graphics("input/images/Fig1.generalf.png")
```

The columns "Perceptions" and "Preferences" represent the distinction between these two concepts, usually confused under the label "beliefs" [@castillo_meritocracia_2019]. Perceptions refer to the extent to which people observe that meritocracy functions or apply in their society, which relates to items such as "Hard work is important to get ahead in society". Preferences refer to normative expectations that are frequently linked to a "should" expression (e.g. whether hard work should be related to payment). The rows in Figure \@ref(fig:merit-model) consider the distinction between meritocratic and non-meritocratic dimensions [@reynolds_perceptions_2014], often treated as different ends of the same continuum in previous research. Non-meritocratic elements refer to the use of resources such as personal contacts and/or family advantages to get ahead in life.

The ISSP survey (inequality module) has some items that researchers have used to measure each of the four different dimensions of meritocracy depicted here, but in a rather inconsistent manner. In the next section, we propose a classification of the ISSP meritocracy items into the different dimensions suggested in our multidimensional model depicted in Figure \@ref(fig:merit-model) as well as an empirical test of this model.


# Methodology

```{r message=FALSE, warning=FALSE, include=FALSE, echo=FALSE}
  #RUN THIS BEFORE THE ANALYSIS
  pacman::p_load(knitr)
  table_format = if(is_html_output()) {
    "html"
  } else if(is_latex_output()) {
    "latex"
  }

  table_format2 = if(is_html_output()) {
    T
  } else if(is_latex_output()) {
    F
  }
```

The analysis is organized into two studies. The first study is an analysis of the multidimensional model for measuring meritocratic beliefs using ISSP data. Based on the results of this first study, the second study recommends some modifications and expansions of the ISSP items in order to tap better each of the dimensions identified in the study of meritocratic beliefs.

# Study 1: Analyzing meritocratic beliefs with ISSP data

## Data

The data corresponds to the social inequality module from the International Social Survey Programme (ISSP), the most specialized international comparative survey in perceptions, attitudes, and beliefs about inequality-related issues [  @issp-research-groupInternationalSocialSurvey2017]. This wave corresponds to 2009 and covers attitudes towards a series of topics dealing with social inequality across 41 countries and 56,021 individuals. Although there is data available from this module for a more recent wave (2019), the 2009 wave contains relevant items for studying meritocracy that unfortunately are not present in the last wave (details about which items are missing in the last 2019 wave are presented in study 2, Table \@ref(tab:table-indicadores)). Table \@ref(tab:countries) (appendix) shows details about the sample of countries in the ISSP 2009 data.

## Variables

There are a series of indicators in the ISSP survey that we classified in our meritocracy conceptual scheme, as presented below in Table \@ref(tab:table-issp):

```{r table-issp, echo=FALSE}
 # if (!require("pacman")) install.packages("pacman")
 # remotes::install_github('haozhu233/kableExtra@a6af5c0')  # for problems with collapse_rows()
pacman::p_load(knitr, kableExtra, dplyr)
  table_format = if(knitr::is_html_output()) {
    "html"
  } else if(knitr::is_latex_output()) {
    "latex"
  }

  tableissp <- read.csv(file = "input/tables/table-issp.csv",header = 1,sep = ";",encoding = "UTF-8") # call file generated externally for the table
  cnames <- c("Component", "Dimensions","Item")
  cap <- "Items of the ISSP meritocratic perceptions and preferences measures"

  knitr::kable(tableissp, table_format, booktabs = T, linesep = "",col.names = cnames, caption = cap) %>%
    kableExtra::kable_styling(
      full_width = F,
      latex_options = c("hold_position"),
      position = "center",
      font_size = 10,
      bootstrap_options=c("striped", "bordered")) %>%
    kableExtra::column_spec(column = 1, width = "2cm", ) %>%
    kableExtra::column_spec(column = 2,width = "5cm") %>%
    kableExtra::column_spec(column = 3,width = "8cm") %>%
    kableExtra::collapse_rows(columns = 1:2,valign = "middle")
```

- _Perception of meritocracy/non-meritocracy_: for operationalizing perceptions the closest set of ISSP's indicators comes from the question asking about perceptions for opportunities to get ahead, which are usually considered as "meritocratic beliefs" in previous studies. The general heading of the battery is: _"To begin we have some questions about opportunities for getting ahead. Please tick one box for each of these to show how important you think it is for getting ahead in life."_ This is followed by a list of statements to be rated from 1 to 5: essential, very important, fairly important, not very important, not important at all.

The classification of the items is based on criteria of internal motivation (meritocratic) and structural constraints (non-meritocratic). There were two items from the battery that were excluded from the analysis as they would not fit into the classification. The first one was "having good education yourself" since it was not clear whether this could be due to individual motivation or system opportunities, and the second was "giving bribes", as introduced elements of criminality that were beyond a non-meritocratic perception.

- _Preferences for meritocracy-non meritocracy_: for the operationalization of normative preferences we used a list of items related to reasons for pay battery. The ISSP question was: _In deciding how much people ought to earn, how important should each of these things be, in your opinion_, rated in the same _essential-non important at all_ scale (1 to 5) as the questions for meritocratic perceptions.

## Methods

The estimation of the measurement model was performed using Confirmatory Factor Analysis (CFA). CFA was conducted using the `lavaan` R package (version 0.6-3; @rosseel_lavaan_2012a), with diagonally weighted least squares (DWLS) estimation due to the items' ordinal level of measurement [@kline_principles_2016; @rosseel_lavaan_2012a]. As recommended by @brown_confirmatory_2015, we assessed model fit by jointly considering the comparative fit index and Tucker-Lewis Index (CFI and TLI; acceptable fit > 0.95), Root of the average squared residual approximation (RMSEA; acceptable fit < 0.08),  Chi-square: (p-value; acceptable fit > 0.05, and Chi-square ratio > 3).

## Results

### Descriptive analyses

Figure \@ref(fig:likert-issp) shows the distribution of responses across the selected items in their corresponding dimensions. On the one side, we observe a high degree of importance attributed to factors such as hard work and ambition for getting ahead, concentrating 94.9% and 92.8% in the _fairly important_ to _essential_ categories, respectively. By contrast, the perception of non-meritocratic aspects is rated lower than the meritocratic ones, particularly for gender, race, and political connections. Regarding normative preferences, we observe that the meritocratic ones are deemed as important (from fairly to essential) for nearly the whole sample, decreasing slightly for the non-meritocratic ones. Still, we have to consider that the preferences for non-meritocratic aspects, in this case, refer to the distributive principle of need rather than personal background (as in the perceptions of non-meritocracy). Such inconsistency between the target of the items for perceptions an preferences is one of the issues to deal with in study 2.

```{r build-likert}
  load(file = "input/data/proc/data_s1.RData")
  if (!require("pacman")) install.packages("pacman")
  pacman::p_load(dplyr,sjPlot, ggplot2, sjlabelled,sjmisc, ggpubr)
  likert_issp<- data_s1 %>%
    dplyr::select(hwork,ambition,wealthy,pareduc,
                  race,gender,people,polcone,
                  welljob,hardjob,family,child) %>% na.omit() #Subset variables
  # Set labels for each variable
  likert_issp <- sjlabelled::set_label(likert_issp,
                                       label = c("Hard work",
                                                 "Having ambition",
                                                 "Wealthy family",
                                                 "Educated parents",
                                                 "Race",
                                                 "Gender",
                                                 "Knowing people",
                                                 "Political connections",
                                                 "Well job",
                                                 "Hard job",
                                                 "Support family",
                                                 "Has children"))
  #Reverse coding (ONLY) for plot
  likert_issp <- sjmisc::rec(likert_issp, rec="rev", append=FALSE)
  #Set value labels for plot
  likert_issp <-
    sjlabelled::set_labels(likert_issp,
                           labels = c("Essential","Very important","Fairly important",
                                      "Not very important","Not important at all"))

  # Declare ggplot2 features
  ggplot2::theme_set(ggplot2::theme(panel.background = ggplot2::element_rect(fill = "gray85",
                                                                             colour = "gray85"),
                                    panel.border = ggplot2::element_blank(),
                                    axis.text.y = ggplot2::element_text(size = 13,
                                                                        hjust = 1),
                                    title = ggplot2::element_text(size = 13,
                                                                  face = "bold"),
                                    legend.text = ggplot2::element_text(size = 12),
                                    plot.caption = ggplot2::element_text(size = 10,
                                                                         face = "plain",
                                                                         hjust = 1)))
  #Plot 1: Perception meritocratic
  p1<- likert_issp %>%
    dplyr::select(hwork_r:ambition_r) %>%
    sjPlot::plot_likert(geom.colors = "PuBu",
                        grid.range  =  c (1.2 , 1.2),
                        title = "a. Perception meritocratic",
                          geom.size = c(0.62),
                          catcount = 5,
                          expand.grid = T,
                          values  =  "sum.outside",
                          reverse.colors = T,
                          reverse.scale = F,
                          show.n = FALSE) +
    ggplot2::theme(legend.position = "none")
  #Plot 2: Perception Non-meritocratic
  p2<-likert_issp %>%
    dplyr::select(wealthy_r:polcone_r) %>%
    sjPlot::plot_likert(geom.colors = "PuBu",
                        grid.range  =  c (1.2 , 1.2),
                        title = "b. Perception Non-meritocratic",
                          geom.size = c(0.9),
                          catcount = 5,
                          expand.grid = T,
                          values  =  "sum.outside",
                          reverse.colors = T,
                          reverse.scale = F,
                          show.n = FALSE)  +
    ggplot2::theme(legend.position = "none")
  #Plot 3: Preference meritocratic
  p3<-likert_issp %>%
    dplyr::select(welljob_r:hardjob_r) %>%
    sjPlot::plot_likert(geom.colors = "PuBu",
                        grid.range  =  c (1.2 , 1.2),
                        title = "c. Preference meritocratic",
                          geom.size = c(0.62),
                          catcount = 5,
                          expand.grid = T,
                          values  =  "sum.outside",
                          reverse.colors = T,
                          reverse.scale = F,
                          show.n = FALSE) +
    ggplot2::theme(legend.position = "none")
  #Plot 4: Preference Non-meritocratic
  p4<-likert_issp %>%
    dplyr::select(family_r:child_r) %>%
    sjPlot::plot_likert(geom.colors = "PuBu",
                        grid.range  =  c (1.2 , 1.2),
                        title = "d. Preference Non-meritocratic",
                          geom.size = c(0.62),
                          catcount = 5,
                          expand.grid = T,
                          values  =  "sum.outside",
                          reverse.colors = T,
                          reverse.scale = F,
                          show.n = FALSE) +
    ggplot2::theme(legend.position = "none")

  #Legend: Extract legend for the final plot using ggpubr
  leg<- ggpubr::as_ggplot(
    ggpubr::get_legend(
      dplyr::select(likert_issp, family_r:child_r) %>%
        sjPlot::plot_likert(geom.colors = "PuBu", catcount = 5) +
        ggplot2::scale_fill_brewer(
          breaks = c(5:1),
          direction = -1,
          labels = c("Not important at all","Not very important","Fairly important",
                     "Very important","Essential")) +
        ggplot2::theme(legend.position = "bottom")
      )
    )
```

```{r likert-issp,fig.height=11,fig.width=11,fig.cap="Distribution of responses in the ISSP meritocracy items", out.width='80%'}
  # dev.copy(png,'output/images/Fig2.plotlikert-study1.png', width = 800, height = 600) # save image
  if (!require("pacman")) install.packages("pacman")
  pacman::p_load(cowplot, dplyr)
  #Final plot
  cowplot::add_sub(
    cowplot::plot_grid(p1,p2,p3,p4,leg, #plot 1,2,3,4 and legend (bottom)
      align = "hv",
      axis = "a",
      nrow = 5, #5 plots
      ncol = 1, #1 column
      rel_heights = c(1,2,1,1,0.25) #fig size within plot
      ),
    label = paste0(
      "Source: Authors calculation based on International Social Survey Programme - Social Inequality 2009",
      " (n=",dim(likert_issp)[1],")"
      ),        # Caption: source and sample size
    size = 10,  # Caption font size
    hjust = 0.25# Caption align
    ) %>%
    cowplot::ggdraw()
    # dev.off()
```

In terms of the association between the indicators, Figure \@ref(fig:corr-issp) shows the polychoric correlation matrix. Firstly, according to the criteria suggested by @cohen_statistical_1988 for effect size, we observe in general that the moderate to high associations are between the pairs of items representing each of the four dimensions described in Table \@ref(tab:table-issp). The exception here is the dimension of non-meritocratic perception, in which six items appear mostly associated by pairs according to their specific topics (family background, personal background, and connections). Still, between this same set of items, moderate correlations could anticipate a single latent factor underlying non-meritocratic perceptions, which is tested next in the confirmatory factor analysis model.

```{r corr-issp,fig.cap = "Perceptions and preferences for ISSP  meritocracy items' polychoric correlations", fig.align='center',fig.height=6,fig.width=8}
  # dev.copy(png,'output/images/Fig3.plotcor-study1.png', width = 800, height = 600) # save image
  load(file = "input/data/proc/data_s1.RData")
  if (!require("pacman")) install.packages("pacman")
  pacman::p_load(dplyr, corrplot, lavaan)
  # create polychoric correlation matrix
  cor_issp<-
    data_s1 %>%
    dplyr::select(hwork,ambition,wealthy,pareduc,
                  race,gender,people,polcone,
                  welljob,hardjob,family,child) %>%
    lavaan::lavCor(., ordered=names(.))
  diag(cor_issp) = NA #set diagonal values to NA
  # Set Row names of the matrix
  rownames(cor_issp) <- c("A. Hard work",
                         "B. Having ambition",
                         "C. Wealthy family",
                         "D. Educated parents",
                         "E. Race",
                         "F. Gender",
                         "G. Knowing people",
                         "H. Political connections",
                         "I. Well job",
                         "J. Hard job",
                         "K. Support family",
                         "L. Has children")
  #set Column names of the matrix
  colnames(cor_issp) <-c("(A)", "(B)","(C)","(D)","(E)","(F)","(G)",
                         "(H)", "(I)","(J)","(K)","(L)")

  #Plot the matrix using corrplot
  corrplot::corrplot(cor_issp,
    method = "color",
    addCoef.col = "#000390",
    type = "upper",
    tl.col = "black",
    col=colorRampPalette(c("white","#0068DC"))(12),
    bg = "white",
    na.label = "-")
    # dev.off()
```

### Confirmatory Factor Analysis

Table \@ref(tab:sum-fit-issp) shows the results of the estimation of two confirmatory models. The first one (First Order) corresponds to a model that estimates four factors, each for one of the dimensions of the multidimensional framework for meritocratic beliefs presented in  Table \@ref(tab:table-issp), with only regular fit indicators (CFI=0.959, TLI=0.944, RMSEA=0.098, $\chi^2$(df=48)= 21308.535). Further analysis showed that the sources for poor fit were mostly related to the items of the non-meritocratic perceptions, which as mentioned above displayed correlations among them not taken into account in this model specification.

```{r sum-fit-issp}
  load(file = "input/data/proc/data_s1.RData")
  if (!require("pacman")) install.packages("pacman")
 # pacman::p_load(dplyr, knitr,lavaan)
  library(kableExtra)
  table_format = if(knitr::is_html_output()) { #conditional instructions for kable
    "html" #if html set "html" in format
  } else if(knitr::is_latex_output()) {
    "latex"#if latex set "latex" in format
  }

  # meassurement model: First order
  cfa_perpref1 <- '
  	  # latent variables
  	  percmerit =~ hwork + ambition
  	  percnmerit=~ wealthy + pareduc +race + gender +people + polcone
  	  prefmerit =~ welljob + hardjob
  	  prefnmerit=~ family + child
  	  '
  # Model fit: First order
  fit_perpref1 <- lavaan::cfa(cfa_perpref1, data = data_s1,ordered = T)

  # meassurement model: Second order
  cfa_perpref2 <- '
  	  # latent variables
  	  percmerit =~ hwork + ambition
  	  parents =~ wealthy + pareduc
  	  backgrd =~ race + gender
  	  networks=~ people + polcone
  	  percnmerit=~ parents + backgrd + networks
  	  prefmerit =~ welljob + hardjob
  	  prefnmerit=~ family + child
  	  '
  # Model fit: second order
  fit_perpref2 <- lavaan::cfa(cfa_perpref2, data = data_s1,ordered = T)

  # extract fit indices from models and add to table
  sum_fit_issp<- dplyr::bind_rows(
    lavaan::fitmeasures(fit_perpref1)[c("chisq","df","cfi","tli","rmsea")],
    lavaan::fitmeasures(fit_perpref2)[c("chisq","df","cfi","tli","rmsea")]
    )

  # Customize object
  sum_fit_issp$mod <- c("First order","Second order")
  sum_fit_issp$nobs <- c(lavaan::nobs(fit_perpref2),lavaan::nobs(fit_perpref2))
  sum_fit_issp$est <- c("DWLS","DWLS")
  sum_fit_issp <- dplyr::select(sum_fit_issp,mod,nobs,est,dplyr::everything())
  colnames <- c("Model","$N$","Estimator","$\\chi^2$","df","CFI","TLI","RMSEA")

  # Create table
  table_issp_fits <-
    knitr::kable(sum_fit_issp, format=table_format, digits=3, booktabs=T,
                 col.names=colnames,
                 caption = "Summary fit indices according to model",
                 escape = FALSE) %>%
    kableExtra::kable_styling(font_size = 10,
                              full_width = F,
                              latex_options = "HOLD_position",
                              bootstrap_options=c("striped", "bordered"))
  table_issp_fits
```

Attending to the sources of poor fit from the first estimated confirmatory model, we specified a second model that keeps the basic four-dimensional structure but generates an additional model for the non-meritocratic perceptions as depicted in Figure \@ref(fig:meas02-issp). In this model, the pairs of items in this dimension form three latent factors which at the same time generate a second-order factor of non-meritocratic perceptions, improving the fit of the model significantly.

```{r meas02-issp, echo=FALSE, fig.cap = "Descriptive plot", fig.align='center',fig.cap="Second-order confirmatory factor analysis model using ISSP indicators of Perceptions and Preferences for Meritocracy"}
 knitr::include_graphics('output/images/figure4.PNG')
```

Regarding the correlations between the factors in Figure \@ref(fig:meas02-issp), we observe that perceptions are correlated with preferences, but more strongly for the meritocratic ($r=0.46, p<0.01$) than for the non-meritocratic ($r=0.27,p<0.01$) dimensions. Secondly, both perceptual dimensions (meritocratic and non-meritocratic) depict a moderate positive correlation ($r=0.30, p<0.01$), suggesting that they are not the opposite poles of the same continuum as some previous studies assume. Something similar occurs for the correlation between the two dimensions of preferences ($r=0.25,p<0.01$).

Based on the previous measurement validation, next we assess some of the potential of the proposed measurement strategy for cross-national comparisons of meritocratic beliefs. In this line, Figure \@ref(fig:scat1) depicts the correlation of factor scores for meritocratic perceptions and meritocratic preferences at the country level ($r=0.65,p<0.01$). For instance, Bulgaria (BGR) and the United States (USA) appropriately represent the positive association between perception and preferences. In other words, countries that perceived merit in their society as an essential factor to get ahead in life also consider that effort and talent should be determinant factors in how much an individual earns. On the other hand, in countries with lower perceived meritocracy, preferences are also low, where Denmark (DNK) and Venezuela (VEN) are representative cases of this association.

Another finding depicted by Figure \@ref(fig:scat1) is the positive association of non-meritocratic perceptions with meritocratic preferences ($r=0.55,p<0.01$), showing that countries like Bulgaria (BGR) and Philipines (PHL) represent cases with higher non-meritocratic perceptions and higher preferences for meritocracy. In other words, in societies where people perceive higher importance of non-meritocratic aspects to get ahead in life, people also prefer that merit should be a determinant factor in wages. On the other side, countries like Sweden (SWE) or Denmark (DNK), both Scandinavian societies with strong welfare systems, represent contexts in which non-meritocratic aspects are not described as important, and merit is not considered as a factor that should be relevant for wages. This finding, particularly the positive association between non-meritocratic perception and meritocratic preferences, opens the question of to what extent meritocratic preferences are capable to hold even under evidence of a large amount of perceived non-meritocracy .

```{r scat1, fig.cap="Cross-national comparison of non-meritocratic and meritocratic perceptions with meritocratic preference",fig.height=6, fig.width=12}
  load(file = "input/data/proc/data_s1.RData")
  if (!require("pacman")) install.packages("pacman")
 pacman::p_load(dplyr, kableExtra, knitr,lavaan,countrycode,ggplot2,haven,gridExtra)
  table_format = if(knitr::is_html_output()) { #conditional instructions for kable
    "html" #if html set "html" in format
  } else if(knitr::is_latex_output()) {
    "latex"#if latex set "latex" in format
  }

  # meassurement model: Second order
  cfa_perpref2 <- '
  	  # latent variables
  	  percmerit =~ hwork + ambition
  	  parents =~ wealthy + pareduc
  	  backgrd =~ race + gender
  	  networks=~ people + polcone
  	  percnmerit=~ parents + backgrd + networks
  	  prefmerit =~ welljob + hardjob
  	  prefnmerit=~ family + child
  	  '
  # Model fit: second order
  
  fit_perpref2 <- lavaan::cfa(cfa_perpref2, data = data_s1,ordered = F)
  
  df_proc<- data_s1 %>% select(id,v5,wealthy:hardjob)  
  df_proc$ccode <- as.numeric(data_s1$v5)   
  
  
  predicted2 <- lavPredict(fit_perpref2,newdata = data_s1)  
  
  idx <- lavInspect(fit_perpref2, "case.idx")
  fscores <- lavPredict(fit_perpref2)
  ## loop over factors
  for (fs in colnames(fscores)) {
    df_proc[idx, fs] <- fscores[ , fs]
  }

  df_proc <-  df_proc %>%  select(id,ccode,percmerit,prefmerit,prefnmerit,percnmerit) %>% na.omit()  
  
  df_proc$clab <- countrycode(sourcevar = df_proc$ccode,
                            origin = "iso3n",
                            destination = "iso3c")


avg_count <-  
  df_proc %>% group_by(clab) %>% summarise(prefmerit=mean(prefmerit),
                                            percmerit=mean(percmerit),
                                            prefnmerit=mean(prefnmerit),
                                           percnmerit=mean(percnmerit),
                                           pop=n()
                                           )

# idea: por continentes o regiones del mundo
# avg_count %>% filter(clab %in% c("ARG","VEN","CHL"))

avg_count$continent <- countrycode(sourcevar = avg_count$clab,
                            origin = "iso3c",
                            destination = "continent")

avg_count$region <- countrycode(sourcevar = avg_count$clab,
                            origin = "iso3c",
                            destination = "region23")

avg_count$country <- countrycode(sourcevar = avg_count$clab,
                            origin = "iso3c",
                            destination = "country.name")

# create figure 1: perception merit by preferences merit
figure1 <- 
ggplot(avg_count, aes(x=percmerit, y=prefmerit)) +
  # geom_point() + 
  geom_text(label=as.character(avg_count$clab)) +
  scale_x_continuous(limits = c(-0.6,0.6))+
  scale_y_continuous(limits = c(-0.6,0.6))+
  geom_smooth(method = "lm",fullrange=TRUE) +
  xlab("Meritocratic perception")+
  ylab("Meritocratic preference")  
# create figure 2: perception non-merit by preferences merit
figure2 <- 
ggplot(avg_count, aes(x=percnmerit, y=prefmerit)) +
  # geom_point() + 
  geom_text(label=as.character(avg_count$clab)) +
  scale_x_continuous(limits = c(-0.6,0.6))+
  scale_y_continuous(limits = c(-0.6,0.6))+ 
  geom_smooth(method = "lm",fullrange=TRUE) +  
  geom_smooth(method = "lm") +
  xlab("Non-meritocratic perception")+
  ylab("Meritocratic preference") 

  
grid.arrange(figure1, figure2, ncol = 2,
             bottom = grid::textGrob(label = paste0("Source: Authors calculation based on International Social Survey Programme - Social Inequality 2009",
      " (n=",dim(df_proc)[1],")"),
                                     hjust = 0.1,
                                     gp = grid::gpar(fontface = 1, fontsize = 9)))
```

Another possibility to explore within this multidimensional framework of meritocratic beliefs is the differences between countries. For instance, when comparing societies based on their level of industrialization [@ishida_trends_2005], Figure \@ref(fig:scat2) shows that early and late-industrialized countries exhibit a similar association between meritocratic perceptions and preferences ($r=0.67, p<0.05$; $r=0.68, p<0.01$, respectively). However, when analyzing the association between non-meritocratic perception and meritocratic preferences, industrialized nations exhibit a strong positive correlation ($r=0.75, p<0.01$), which is not the case for late-industrialized countries ($r=0.29, p>0.05$). A possible interpretation is that the perception of non-meritocracy in less industrialized societies threatens the meritocratic ideal, which is not the case for the industrialized ones. Still, this preliminary analysis only attempts to show some possiblities that open up when introducing a multidimensional perspective for studying meritocratic beliefs 

```{r scat2, fig.cap="Cross-national comparison between industrialized and late-industrialized",fig.height=10, fig.width=10}
  load(file = "input/data/proc/data_s1.RData")
  if (!require("pacman")) install.packages("pacman")
  pacman::p_load(dplyr, kableExtra, knitr,lavaan,countrycode,ggplot2,haven,
                 gridExtra)
  table_format = if(knitr::is_html_output()) { #conditional instructions for kable
    "html" #if html set "html" in format
  } else if(knitr::is_latex_output()) {
    "latex"#if latex set "latex" in format
  }

  # meassurement model: Second order
  cfa_perpref2 <- '
  	  # latent variables
  	  percmerit =~ hwork + ambition
  	  parents =~ wealthy + pareduc
  	  backgrd =~ race + gender
  	  networks=~ people + polcone
  	  percnmerit=~ parents + backgrd + networks
  	  prefmerit =~ welljob + hardjob
  	  prefnmerit=~ family + child
  	  '
  # Model fit: second order
  
  fit_perpref2 <- lavaan::cfa(cfa_perpref2, data = data_s1,ordered = F)
  
  df_proc<- data_s1 %>% select(id,v5,wealthy:hardjob)  
  df_proc$ccode <- as.numeric(data_s1$v5)   
  
  
  predicted2 <- lavPredict(fit_perpref2,newdata = data_s1)  
  
  idx <- lavInspect(fit_perpref2, "case.idx")
  fscores <- lavPredict(fit_perpref2)
  ## loop over factors
  for (fs in colnames(fscores)) {
    df_proc[idx, fs] <- fscores[ , fs]
  }

  df_proc <-  df_proc %>%  select(id,ccode,percmerit,prefmerit,prefnmerit,percnmerit) %>% na.omit()  
  
  df_proc$clab <- countrycode(sourcevar = df_proc$ccode,
                            origin = "iso3n",
                            destination = "iso3c")


avg_count <-  
  df_proc %>% group_by(clab) %>% summarise(prefmerit=mean(prefmerit),
                                            percmerit=mean(percmerit),
                                            prefnmerit=mean(prefnmerit),
                                           percnmerit=mean(percnmerit),
                                           pop=n()
                                           )

# idea: por continentes o regiones del mundo
# avg_count %>% filter(clab %in% c("ARG","VEN","CHL"))

avg_count$continent <- countrycode(sourcevar = avg_count$clab,
                            origin = "iso3c",
                            destination = "continent")

avg_count$region <- countrycode(sourcevar = avg_count$clab,
                            origin = "iso3c",
                            destination = "region23")

avg_count$country <- countrycode(sourcevar = avg_count$clab,
                            origin = "iso3c",
                            destination = "country.name")

western <- 
avg_count %>%
  filter(continent=="Europe"| clab %in% c("USA","AUS","NZL")) 

nonwestern <- 
avg_count %>%
  filter(continent=="Asia" | clab %in% c("VEN","CHL","ARG","ZAF"))

indus <-  avg_count %>% 
  filter(region %in% c("Northern America","Western Europe")) 

lateindus <-  avg_count %>% 
  filter(!region %in% c("Northern America","Western Europe")) 


indus <-  avg_count %>% 
  filter(country %in% c("Australia","Austria","Belgium","Switzerland","Germany","Denmark","Finland","France","United Kingdom","Iceland","Norway", "Sweden","United States")) 

lateindus <-  avg_count %>% 
  filter(!country %in% c("Australia","Austria","Belgium","Switzerland","Germany","Denmark","Finland","France","United Kingdom","Iceland","Norway", "Sweden","United States")) 




# Western countries-------------------------------------------------------------
wesmerit <- 
indus %>%  
ggplot(aes(x=percmerit, y=prefmerit)) +
  # geom_point() + 
  geom_text(label=as.character(indus$clab)) +
  scale_x_continuous(limits = c(-0.6,0.6))+
  scale_y_continuous(limits = c(-0.6,0.6))+
  geom_smooth(method = "lm",fullrange=TRUE) +
  xlab("Meritocratic perception")+
  ylab("Meritocratic preference") +
  ggtitle("Industrialized countries")
wesnonmer <- 
indus %>%  
ggplot(aes(x=percnmerit, y=prefmerit)) +
  # geom_point() + 
  geom_text(label=as.character(indus$clab)) +
  scale_x_continuous(limits = c(-0.6,0.6))+
  scale_y_continuous(limits = c(-0.6,0.6))+ 
  geom_smooth(method = "lm",fullrange=TRUE) +
  xlab("Non-meritocratic perception")+
  ylab("Meritocratic preference") +
  ggtitle("Industrialized countries")

# Non western countries --------------------------------------------------------
nonwesmer <- 
lateindus %>%  
ggplot(aes(x=percmerit, y=prefmerit)) +
  # geom_point() + 
  geom_text(label=as.character(lateindus$clab)) +
  scale_x_continuous(limits = c(-0.6,0.6))+
  scale_y_continuous(limits = c(-0.6,0.6))+
  geom_smooth(method = "lm",fullrange=TRUE) +
  xlab("Meritocratic perception")+
  ylab("Meritocratic preference") +
  ggtitle("Late industralized countries")
nonwesnonmer <- 
lateindus %>%  
ggplot(aes(x=percnmerit, y=prefmerit)) +
  # geom_point() + 
  geom_text(label=as.character(lateindus$clab)) +
  scale_x_continuous(limits = c(-0.6,0.6))+
  scale_y_continuous(limits = c(-0.6,0.6))+
  geom_smooth(method = "lm",fullrange=TRUE) +
  xlab("Non-meritocratic perception")+
  ylab("Meritocratic preference") +
  ggtitle("Late industralized countries")

grid.arrange(wesmerit,wesnonmer,
             nonwesmer,nonwesnonmer, ncol = 2,
             bottom = grid::textGrob(label = paste0("Source: Authors calculation based on International Social Survey Programme - Social Inequality 2009"),
                                     hjust = 0.2,
                                     gp = grid::gpar(fontface = 1, fontsize = 9)))
```

## Discussion Study 1

ISSP is - and probably it will continue to be - the most widely used dataset for comparative studies of meritocratic beliefs. Although several ISSP items were not conceived originally with this end, they have been extensively used to operationalize different aspects of meritocracy. In this study, we ordered and classified ISSP items, which have been previously used for measuring meritocratic beliefs, into four different dimensions: perceptions and preferences, and meritocracy and non-meritocracy. The confirmatory analysis gave evidence of an adequate fit of the multidimensional model to the ISSP data, this is, it is possible to identify perceptions and preferences for meritocracy and non-meritocracy as four related but different constructs. Regarding the non-meritocratic dimensions, we can preliminary conclude that the wide use of reverse-coding for non-meritocratic items attempting to measure meritocratic perceptions or preferences, is not an adequate operationalization. Meritocracy and non-meritocracy are related but different concepts, meaning that it is theoretically possible to find different combinations at individual and contextual levels. This finding opens a series of avenues for future research that are considered in the conclusions.

Despite the advantages of using ISSP data for studying meritocratic beliefs, there are some aspects to be aware of regarding the measurement quality offered by the available items. Some of the items are not really coherent across dimensions, as for instance, meritocratic perceptions are related to ambition and hard work, whereas meritocratic preferences deal with how well a job is done. Such differences impose limitations for a comparative analysis between pereptions and preferences. A better operationalization would require more alignment between the different sides of the same concept, this is, that perceptions and preferences point to the same object of analysis. Furthermore, the instrument is rather unbalanced given the larger amount of non-meritocratic perception items (six) when compared to the number items related to the other dimensions (two). These limitations are taken into account next in the design of study 2.


# Study 2: A proposal for a multidimensional measure of meritocratic beliefs

Taking the analysis of meritocratic beliefs with ISSP as a departing point, the following study offers and test a new measurement instrument that attempts to overcome some limitations identified in the previous study. In this sense, the analysis with ISSP data can be considered as an _inductive_ exercise, taking the items and data available and attempting to adjust this information to the proposed multidimensional conceptual model. In the following study we take a complementary _deductive_ approach, departing from the conceptual model for the design of a measurement instrument. However, this second approach does not start from scratch, as it is based on ISSP items as much as possible for the sake of comparability with previous studies. The two major differences are: a) it incorporates a balanced and minimalistic representation of items for each of the four dimensions,and b) attempts to maintain the coherence in the topics asked across dimensions (for instance, "effort" in items for both perceptions and preferences).

## Data

The data comes from an online survey that was part of a larger study on meritocracy and distributive preferences developed in Chile in 2020, funded by the Chilean National Scientific Agency (ANID). The questionnaire was programmed in Qualtrics and the fieldwork was conducted by an external online survey agency ([netquest.com](www.netquest.com)) between December 2019 and January 2020. The sample was selected from a non-probabilistic quota design in three large cities in Chile (Santiago, Concepción & Antofagasta). The quotas for gender, age, and educational levels were generated based on a survey by the Public Studies Center [@cep_encuesta_2019], which is a well-regarded counterpart agency of the ISSP (International Social Survey Programme) in Chile. A total sample of 2,141 individuals was collected, excluding those who did not sign the informed consent and those not answering the meritocracy instrument. There were no significant differences between our sample and the wider population for most socio-demographic characteristics, except for the educational level (see Table \@ref(tab:rep-samp) in Appendix). As is often the case with online surveys, there were some limitations in achieving the quotas for lower educational levels [@zhang_quota_2018; @boas_recruiting_2020]. This survey was designed as a three-wave panel and the data used in this analysis corresponds to the first wave.

All participants signed the required informed consent and the survey implementation was approved by the ethical committee from Pontificia Universidad Católica de Chile, protocol ID 150811008, April 6th 2016.


## Study design

### Instrument

The proposed items' battery of meritocratic perceptions and preferences consisted of eight indicators, two for each of the four dimensions listed earlier: perceptions (meritocratic/non-meritocratic) and preferences (meritocratic/non-meritocratic). Two main criteria oriented this design. The first one was usability in social survey research, for which the scale length must attend spacer restrictions in such studies. Nevertheless, at the same time, the scale should offer possibilities of accounting for measurement error through factor analysis techniques. Although a rule of thumb in latent measurement suggests at least three indicators per dimension, we still opted for two to count with a brief scale. Although such a decision posits some limitations for modeling measurement error, still allows for factor analysis and is a common approach in previous social survey studies with limited items (for instance see @davidov_measurement_2009). The second criterion is to expand the possibilities of comparability with previous studies on meritocracy, by considering some of the items previously used in this research area. To this regard, some of the items were adapted from the items battery "reasons to get ahead" (ISSP/GSS), which has been widely used for operationalizing meritocracy in international research [@mijs_paradox_2019; @duru-bellat_who_2012; @reynolds_perceptions_2014]. 

The items, organized according to their respective dimensions, are presented in Table \@ref(tab:table-indicadores). These eight likert-type items have five response alternatives, ranging from "Completely disagree"(1) to "Completely agree" (5). The table presents an additional column with the respective equivalent items from ISSP 2009/2019. With this information it is possible to have a more clear picture of the areas in which the proposed measurement instrument is similar to ISSP and in which ones it differs.


```{r table-indicadores, echo=FALSE}
 if (!require("pacman")) install.packages("pacman")
 # remotes::install_github('haozhu233/kableExtra@a6af5c0')  # for problems with collapse_rows()
 pacman::p_load(knitr, kableExtra, dplyr)
 table_format = if (knitr::is_html_output()) {
   #conditional instructions for kable
   "html" #if html set "html" in format
 } else if (knitr::is_latex_output()) {
   "latex"#if latex set "latex" in format
 }
 tabitems <- read.csv(file = "input/tables/table01.csv",header = 1,sep = ",",encoding = "UTF-8") # call file  generated externally for the table
 tabitems$itemsspa <- NULL
 tabitems[9,] <- tabitems[8,]
 tabitems[9,3] <- "-"
 tabitems[10,] <- tabitems[8,]
 tabitems[10,3] <- "-"
 tabitems$issp <- c("How important is hard work?","-",
                    "How important is coming from a wealthy family?", 
                    "How important is knowing the right people",
                    "In deciding how much people ought to earn, how important each of these things be (...) How hard he or she works at the job?¹",
                    " (...) How well he or she does the job?¹",
                    "-", "-",
                    "(...) What is needed to support a family?¹²","(...) Whether the person has children to support²")

 cnames <- c("Component", "Dimensions","Items" , "Items ISSP (2009,2019)")
 cap <- "Items' battery for the multidimensional measurement of meritocratic beliefs and their equivalents in ISSP"
 knitr::kable(tabitems, table_format, booktabs = T, linesep = "",col.names = cnames, caption = cap,
              longtable = F, escape = T) %>%
   kableExtra::kable_styling(
     full_width = T,
     latex_options = c("hold_position"),
     position = "center",
     font_size = 10,
     bootstrap_options=c("striped", "bordered")) %>%
   kableExtra::column_spec(column = 1, width = "1.5cm") %>%
   kableExtra::column_spec(column = 2,width = "2 cm") %>%
   kableExtra::collapse_rows(columns = 1:2,valign = "middle") %>%
   kableExtra::footnote(number =  c("Items present only in ISSP 2009",
                                    "ISSP items that are not equivalent with the new measurement proposal"))
```
\pagebreak

### Administration sets

To evaluate the effect of indicator ordering in the responses, three different versions of items' order were designed and randomly assigned to the respondents, as depicted in Figure \@ref(fig:appmod). The scale was presented to the first group (_n = 712_) in the order shown in Table \@ref(tab:table-indicadores) according to perceptions and preferences. For the second group (_n = 717_), the order was reorganized according to perceptions and preferences over the same topic, e.g., for the topic of hard work, the item about perception was followed by the item about preference and the same for the rest of the topics. Finally, for the third group (_n = 712_), the items were presented as completely randomized.

```{r appmod, echo=FALSE, fig.cap = "Survey flow", fig.align='center'}
 knitr::include_graphics('output/images/figure6.png')
```

## Methods

To test the scale's underlying constructs, we employed confirmatory factor analysis models (CFA). The models estimated one factor for each of the four proposed dimensions presented in Table \@ref(tab:table-indicadores). As in study 1, CFA was performed with the `lavaan` R package (version 0.6-3; @rosseel_lavaan_2012a), with diagonally weighted least squares (DWLS) estimation due to the items' ordinal level of measurement [@kline_principles_2016; @rosseel_lavaan_2012a]. The fit indexes and cut-off criteria were the same as the ones used in Study 1.

A pre-registration was made in the OSF platform, available at the following link: [https://osf.io/z45y2](https://osf.io/z45y2/?view_only=adcd496887f2471597b1d6ffb46e492d). This pre-registration includes the hypotheses regarding the four-dimensional conceptual model underlying the scale, the variable measurement levels, the statistical tests to be performed with their respective evaluation parameters, and other important aspects of the research design.

## Results

### Descriptive analyses

The graphs presented in Figure \@ref(fig:plotlikert) display disaggregated and comparable information of the different response categories for each item. Generally, there is more agreement in the perception of non-meritocratic items than in meritocratic ones, while in the preferences, the opposite occurs. Regarding preferences, the predominant role of effort over talent as a criterion of meritocratic preference is noteworthy. All in all, the descriptive results show a critical view of meritocracy, perceiving the operation of non-meritocratic aspects over meritocratic ones, whereas in the preferences the opposite occurs.

```{r produce-likert_s2, include=FALSE}
  if (!require("pacman")) install.packages("pacman")
  pacman::p_load(dplyr,sjPlot, ggplot2, sjlabelled,sjmisc, ggpubr)
  load(file = "input/data/proc/data_s2.RData")
  names(data_s2)
  dat_likert_s2 <- data_s2 %>% dplyr::select(!group) # exclude group variable
  dat_likert_s2 <- sjmisc::rec(dat_likert_s2, rec="rev", append=FALSE)
  names(dat_likert_s2) # reverse coding for likert graph

  table(data_s2$perc_effort)
  table(dat_likert_s2$perc_effort_r) # check ok.
  # update.packages("sjPlot") # please install version 2.8.9 or above
  ggplot2::theme_set(ggplot2::theme(panel.background = ggplot2::element_rect(fill = "gray85",
                                                                             colour = "gray85"),
                                    panel.border = ggplot2::element_blank(),
                                    axis.text.y = ggplot2::element_text(size = 13,
                                                                        hjust = 1),
                                    title = ggplot2::element_text(size = 13,
                                                                  face = "bold"),
                                    legend.text = ggplot2::element_text(size = 12),
                                    plot.caption = ggplot2::element_text(size = 10,
                                                                         face = "plain",
                                                                         hjust = 1)))

  #Plot 1: Perception
  p1<-
    dplyr::select(dat_likert_s2,perc_effort_r:perc_netw_r) %>%
    sjPlot::plot_likert(geom.colors = "PuBu",
                        title = c("a. Perceptions"),
                        geom.size = 0.8,
                        axis.labels = c("Effort", "Talent", "Rich Parents", "Contacts"),
                        catcount = 4,
                        cat.neutral = 3,
                        grid.range  =  c (1.2 , 1.2),
                        values  =  "sum.outside",
                        reverse.colors = T,
                        reverse.scale = F,
                        show.n = FALSE) +
    ggplot2::theme(legend.position = "none")

  #Plot 2: Preferences
  p2<-
    dplyr::select(dat_likert_s2,pref_effort_r:pref_netw_r) %>%
    sjPlot::plot_likert(geom.colors = "PuBu",
                        title = c("b. Preferences"),
                        geom.size = 0.8,
                        axis.labels = c("Effort", "Talent", "Rich Parents", "Contacts"),
                        catcount = 4,
                        cat.neutral = 3,
                        grid.range  =  c (1.2 , 1.2),
                        values  =  "sum.outside",
                        reverse.colors = T,
                        reverse.scale = F,
                        show.n = FALSE)  +
    ggplot2::theme(legend.position = "none")

  #Legend: Extract legend for the final plot using ggpubr
  leg<- ggpubr::as_ggplot(
    ggpubr::get_legend(
    dplyr::select(dat_likert_s2,pref_effort_r:pref_netw_r) %>%
        sjPlot::plot_likert(geom.colors = "PuBu",
                            catcount = 4,
                            cat.neutral = 3) +
      ggplot2::theme(legend.position = "bottom") +
      ggplot2::scale_fill_manual(
        values = c("#b3b3b3ff", "#f1eef6ff", "#bdc9e1ff","#74a9cfff","#0570b0ff"),
        breaks=c("neutral",4,3,2,1),
        labels=c("Neither agree nor disagree","Strongly disagree","Disagree",
                 "Agree","Totally agree")
        )
      )
    )
```

```{r plotlikert, echo=FALSE, fig.align='center', fig.cap="Distribution of responses in the Merit Scale items", fig.height=8, fig.width=11}
  # dev.copy(png,'output/images/Fig6.plotlikert-study2.png', width = 820, height = 600)
  if (!require("pacman")) install.packages("pacman")
  pacman::p_load(cowplot)
  #Final plot
  cowplot::add_sub(
    cowplot::plot_grid(p1,p2,leg, #plot 1,2 and legend (bottom)
      align = "hv",
      axis = "a",
      nrow = 3, #2 plots
      ncol = 1, #1 column
      rel_heights = c(1,1,0.25) #fig size within plot
      ),
    label = paste0("Source: Authors calculations based on Study 2 sample"," (n=",dim(na.omit(dat_likert_s2))[1],")"
      ),        # Caption: source and sample size
    size = 12,  # Caption font size
    hjust = -0.15# Caption align
    ) %>%
    cowplot::ggdraw()
  # dev.off()
```

Attending now to the association among the scale items, Figure \@ref(fig:corpoly) shows the items' polychoric correlations. There are three main aspects to highlight from this correlation matrix.  Firstly, and as expected, the largest correlations are between indicators that correspond to the same factors (dimensions) behind the conceptual model (e.g., perception of meritocracy by effort and by talent, $r=0.52,p<0.01$). Secondly, among these correlations, the highest are those between the non-meritocratic dimensions, both in perceptions ($r=0.73,p<0.01$) and preferences ($r=0.61,p<0.01$). Thirdly, both items for meritocratic preferences (E and F) are the ones that mostly correlate with the rest of the perceptual items, showing medium to high correlations and indicating that the perception  of non-meritocracy would be related to larger meritocratic preferences. Finally, similar to the results of study 1 with ISSP data, we observe no considerable negative correlations between meritocratic and non-meritocratic aspects, undermining previous studies' assumptions that these dimensions would be the opposite poles of one same continuum [@reynolds_perceptions_2014].

```{r corpoly, echo=FALSE, fig.cap = "Perceptions and preferences for meritocracy items' polychoric correlations", fig.align='center'}
  # dev.copy(png,'output/images/Fig7.plotcor-study2.png',width = 800, height = 600) # save image
  if (!require("pacman")) install.packages("pacman")
  load(file = "input/data/proc/data_s2.RData")
  pacman::p_load(dplyr, corrplot, lavaan)
  # generate polychoric matrix
  cor_s2<- data_s2 %>%
    dplyr::select(perc_effort,perc_talent,perc_wpart,perc_netw,pref_effort,pref_talent,pref_wpart,pref_netw) %>%
    lavaan::lavCor(., ordered=names(.))

  diag(cor_s2) = NA

  rownames(cor_s2) <-c(
      "A. Perception Effort",
      "B. Perception Talent",
      "C. Perception Rich parents",
      "D. Perception Contacts",
      "E. Preferences Effort",
      "F. Preferences Talent",
      "G. Preferences Rich parents",
      "H. Preferences Contacts")
  colnames(cor_s2) <-c("(A)", "(B)","(C)","(D)","(E)","(F)","(G)", "(H)")

  corrplot::corrplot(cor_s2,
    method = "color",
    addCoef.col = "#000390",
    type = "upper",
    tl.col = "black",
    col=colorRampPalette(c("white","#0068DC"))(8),
    bg = "white",
    na.label = "-")
  # dev.off()
```

### Confirmatory Factor Analysis

The present section describes the results of the confirmatory factor analysis estimation. The model estimates four latent factors: perception meritocratic, perception non-meritocratic, preferences meritocratic, and preferences non-meritocratic. Each factor is estimated based on two scale items as detailed in Table \@ref(tab:table-indicadores).

The first step in the analysis consists of comparing the model fit indicators for the three versions of the instrument that were randomly assigned to the participants: order according to perceptions/preferences, order according to topics, and a complete random items’ order (see Figure \@ref(fig:appmod)).

```{r model-generation-cfa}
  # Libraries & data
  if (!require("pacman")) install.packages("pacman")
  pacman::p_load(lavaan)
  load(file = "input/data/proc/data_s2.RData")
  # names(data_s2)

  # model
  model_cfa <- '
  perc_merit =~ perc_effort+perc_talent
  perc_nmerit=~perc_wpart +perc_netw
  pref_merit =~ pref_effort+pref_talent
  pref_nmerit=~pref_wpart +pref_netw
  '

  # estimation for each order set
  fit_cfa1 <- lavaan::cfa(model_cfa, data = data_s2[data_s2$group == 1,], ordered = TRUE, std.lv=FALSE)
  fit_cfa2 <- lavaan::cfa(model_cfa, data = data_s2[data_s2$group == 2,], ordered = TRUE, std.lv=FALSE)
  fit_cfa3 <- lavaan::cfa(model_cfa, data = data_s2[data_s2$group == 3,], ordered = TRUE, std.lv=FALSE)
```

```{r table-cfafits, echo=FALSE}
  if (!require("pacman")) install.packages("pacman")
  pacman::p_load(dplyr, kableExtra, knitr)
  table_format = if(knitr::is_html_output()) { #conditional instructions for kable
     "html" #if html set "html" in format
   } else if(knitr::is_latex_output()) {
     "latex"#if latex set "latex" in format
   }
  # extract fit indices from models and add to table
  sum_fit<- dplyr::bind_rows(lavaan::fitmeasures(fit_cfa1)[c("chisq","df","cfi","tli","rmsea")],
                             lavaan::fitmeasures(fit_cfa2)[c("chisq","df","cfi","tli","rmsea")],
                             lavaan::fitmeasures(fit_cfa3)[c("chisq","df","cfi","tli","rmsea")])

  # Customize object
  sum_fit$mod <- c("Version 1","Version 2","Version 3")
  sum_fit$nobs <- c(nobs(fit_cfa1),nobs(fit_cfa2),nobs(fit_cfa3))
  sum_fit$est <- c("DWLS","DWLS","DWLS")
  sum_fit <- dplyr::select(sum_fit,mod,nobs,est,everything())
  colnames <- c("Model","$N$","Estimator","$\\chi^2$","df","CFI","TLI","RMSEA")

  # Create table
  table_cfa_fits <-kable(sum_fit, format=table_format,
                         digits=3,
                         booktabs=T,
                         col.names=colnames,
                         caption = "Summary fit indices according to order versions",
                         escape = FALSE) %>%
    kable_styling(full_width = F,
                  font_size = 10,
                  latex_options = "HOLD_position",
                  bootstrap_options=c("striped", "bordered"))
  table_cfa_fits
```

Table \@ref(tab:table-cfafits) shows the fit indicators of the models estimated for each of the three versions of the items' order described in the methodology. Regardless of the version, all models obtained adequate fit indicators, with CFI's above 0.95 and RMSEA's below 0.08. However, none of the models achieved a non-significant chi-square, as expected in large samples like the one used here. The first version order (perceptions-preferences) was the one obtaining the best fit (CFI=0.993, TLI=0.995, RMSEA=0.034, $\chi2$(df=14)=42.276), whereas version 2 with the fixed order according to merit/non-merit items shows the comparatively worst indicators. The CFA fit indices for the completely randomized items' order (Model 3) keep all the indicators within the acceptable cut-off criteria and controls for possible order effects in the administration of the instrument. The model and parameter estimates for this version are depicted in Figure \@ref(fig:meas02):

```{r meas02, echo=FALSE, fig.cap = "Confirmatory factor analysis of the Perceptions and Preferences for Meritocracy Scale", fig.align='center'}
 # estimation for diagram: summary(fit_cfa3, standardized = TRUE, fit.measures=TRUE)
 knitr::include_graphics('output/images/figure9.png')
```

Attending to the correlations between the latent variables as depicted in Figure \@ref(fig:meas02), meritocratic preferences are moderate to highly correlated with perceptions, both meritocratic ($r=0.457,p<0.01$) and non-meritocratic ($r=0.500,p<0.01$). The correlation between both types of perceptions ($r=-0.044,p>0.05$) and both types of preferences ($r=0.185,p<0.01$) was low, as well as between non-meritocratic preferences and perceptions ($r=-0.059p>0.05$). This last finding gives further evidence regarding the lack of unidimensionality of meritocratic and non-meritocratic aspects as assumed by previous studies.

The measurement of meritocratic beliefs with this new instrument shows, in general, better fit - and therefore better measurement quality - than study 1. However, the comparison between the two studies is unbalanced as we are comparing one particular country (study 2) with the whole set of ISSP countries (study 1). To clear this point, we performed an additional analysis of ISSP data only for the case of Chile. Overall, the results for the chilean ISSP data show a similar fit to the ones of with the complete ISSP dataset (CFI=0.987, TLI=0.980, RMSEA=0.055, $\chi^2$(df=45)= 234), and therefore the instrument of study 2 outperforms their fit indicators.

## Discussion Study 2

The eight-items' battery presented here and the estimation of the confirmatory model with chilean data gives additional evidence for a multidimensional concept of meritocratic beliefs. Despite the good general working of the scale, there are some limitations in interpreting the results given the few items (two) per dimension. As mentioned before, the option of a minimalistic approach in terms of items has advantages and disadvantages: advantages in terms of usability in social surveys with limited space and disadvantages in terms of measurement validity in the estimation of the latent constructs. Regarding the practical use of the measurement instruments, the primary lesson from our study 2 is the importance of distinguishing between the four dimensions. We recommend using the eight-items battery when scholars intend to measure both perceptions and preferences. Alternatively, scholars can use the individual components separately. For instance, researchers interested in the dimension of perception can use only  the four items that assess both the meritocratic and non-meritocratic perception. Furthermore, this measurement proposal can be used for relating the dimensions among themselves (for instance, to what extent the perception of meritocracy is related to the preference of it). It can also serve to studies about how each of these dimensions is associated with or moderated by individual and country level variables.

# Conclusions

Studies that attempt to characterize and compare societies by their support for meritocratic beliefs have used different approaches. As most studies use secondary survey data, and by and large items from the social inequality module from ISSP, they tend to assume that the available indicators represent an underlying meritocratic construct. A review of these studies reveals several non-tested assumptions and the use of similar indicators to represent different constructs and dimensions of meritocracy. As the existence of heterogeneous approaches certainly has consequences for the advancement of the study of meritocracy, this paper presented a comprehensive multidimensional conceptual framework for the empirical study of meritocracy, building upon previous research. We tested the validity of our conceptual framework with two studies. In a first study, this framework was operationalized and tested with ISSP international data. Based on the results with ISSP, a second study proposed some improvements to the measure of meritocracy  with ISSP, which was tested with novel data from a single country case (Chile).

The results of our empirical studies show evidence in favor of a four dimensional model of meritocracy, opening interesting avenues for future comparative research. For instance, distinguishing perceptions from preferences will allow us to evaluate the extent to which different societies are accustomed to, or satisfied with, the perceived level of meritocracy, in terms of differences between what is perceived and what is preferred. Additionally, given that non-meritocratic factors are not necessarily related to meritocratic ones, the multidimensional measurement of meritocratic beliefs makes it possible to assess the perceived legitimacy of practices such as the use of personal contacts and their interference (or not) with meritocratic ideals in different societies. Considering how individual and societal structural factors are related to meritocracy will allow us to gain knowledge about the legitimacy of distribution based on meritocratic criteria. Furthermore, the impact of different configurations of the four-dimensional framework on practices and behaviors, such as corruption, civic involvement, and political alignment, are areas that open up for future development. Such agendas could be especially relevant in times of economic crisis and growing inequalities, which could entail changes in the legitimation of the current distributive structure based on meritocratic ideals.

Besides the areas of research with comparative survey studies as ISSP, single case studies as well as future comparative studies (ISSP included) might benefit from taking into account the measurement instrument for meritocracy proposed here, tested so far with novel Chilean data. The instrument is to some extent comparable to ISSP - as some of its items are equivalent - but improves the balanced measurement of the four dimensions in a minimalistic eight-items’ battery, suitable for survey research. Still, further evidence is needed in order to assess the external validity of the results. Upcoming research in the area of meritocratic beliefs, a growing research agenda, would certainly help to keep improving the quality of the measurement instruments in this area, which is a key enterprise when it comes to assess the support and legitimacy of the meritocratic distribution, particularly in unequal societies. 


# Transparency statement

This research follows a series of open science guidelines as the pre-registration of Study 2 (scale development) as well as the availability of data and codes (R) in a public repository in Github. This document was generated with the R package Rmarkdown and contains the code for all the tables and figures to make it reproducible.

# References

<div id="refs"> </div>  <!-- Although <div> is an HTML tag, this method also works for other output formats such as PDF. -->



\pagebreak

<!-- # Appendix {-} -->

`r if (knitr::is_latex_output()){ '\\appendix'}`

`r if (knitr::is_latex_output()){ '\\section{Appendix}'}`


```{r countries, echo=FALSE}
  load(file = "input/data/proc/data_s1.RData")
  if (!require("pacman")) install.packages("pacman")
  pacman::p_load(dplyr, kableExtra, knitr,lavaan,countrycode,ggplot2,haven,
                 gridExtra)
  table_format = if(knitr::is_html_output()) { #conditional instructions for kable
    "html" #if html set "html" in format
  } else if(knitr::is_latex_output()) {
    "latex"#if latex set "latex" in format
  }
  load(file = "input/data/proc/data_s1.RData")
  if (!require("pacman")) install.packages("pacman")
  pacman::p_load(dplyr, kableExtra, knitr,lavaan,countrycode,ggplot2,haven,
                 gridExtra)
  table_format = if(knitr::is_html_output()) { #conditional instructions for kable
    "html" #if html set "html" in format
  } else if(knitr::is_latex_output()) {
    "latex"#if latex set "latex" in format
  }
 # meassurement model: Second order
  cfa_perpref2 <- '
  	  # latent variables
  	  percmerit =~ hwork + ambition
  	  parents =~ wealthy + pareduc
  	  backgrd =~ race + gender
  	  networks=~ people + polcone
  	  percnmerit=~ parents + backgrd + networks
  	  prefmerit =~ welljob + hardjob
  	  prefnmerit=~ family + child
  	  '
  # Model fit: second order
  
  fit_perpref2 <- lavaan::cfa(cfa_perpref2, data = data_s1,ordered = F)
  
  df_proc<- data_s1 %>% select(id,v5,wealthy:hardjob)  
  df_proc$ccode <- as.numeric(data_s1$v5)   
  
  
  predicted2 <- lavPredict(fit_perpref2,newdata = data_s1)  
  
  idx <- lavInspect(fit_perpref2, "case.idx")
  fscores <- lavPredict(fit_perpref2)
  ## loop over factors
  for (fs in colnames(fscores)) {
    df_proc[idx, fs] <- fscores[ , fs]
  }

  df_proc <-  df_proc %>%  select(id,ccode,percmerit,prefmerit,prefnmerit) %>% na.omit() 
  
  df_proc$clab <- countrycode(sourcevar = df_proc$ccode,
                            origin = "iso3n",
                            destination = "country.name")
avg_count <-  
  df_proc %>% group_by(clab) %>% summarise(N=n())
avg_count <- arrange(avg_count)

# sum(avg_count[, 'N'])
  col.nam <- c("Country","N", "Country", "N")
  footnote <- paste0("N = ", sum(avg_count[, 'N']),". Source: International Social Survey Programme (2009).")

  knitr::kable(bind_cols(avg_count[1:20,],avg_count[21:40,]),
               col.names = col.nam, align = c("l","l","l","l"),linesep = "",
        booktabs=TRUE,format = table_format,escape = FALSE,
        caption = "Sample of Study 1 ") %>%
    kableExtra::kable_styling(full_width = FALSE,
                              latex_options = "HOLD_position",
                              bootstrap_options=c("striped", "bordered"),
                              font_size = 10) %>%
    kableExtra::column_spec(column = c(2,4),width = "1cm") %>% 
    kableExtra::column_spec(column = c(1,3),width = "2.5cm") %>% 
    column_spec(3, border_left = T) %>% 
    kableExtra::footnote(general = footnote, footnote_as_chunk = T,threeparttable = T)
```

\pagebreak


|                     | Sample  |   CEP  |
|---------------------|:-------:|:------:|
| __Gender__          |         |        |
| Men                 | 49,82%  | 50,52% |
| Women               | 50.18%  | 49,47% |
| __Age__             |         |        |
| 18 - 24             | 18,55%  | 18,17% |
| 25 - 34             | 18,86%  | 17,48% |
| 35 - 44             | 19.09%  | 19,98% |
| 45 - 54             | 17,96%  | 19,23% |
| 55 - or more        | 25,54%  | 25.11% |
| __Education__       |         |        |
| Primary  or less    | 2,93%   | 15,88% |
| High school         | 43,23%  | 37,04% |
| Non university      | 32,63%  | 28,93% |
| University or more  | 21,21%  | 18,13% |
Table: `r as.character(paste("(\\#tab:rep-samp)", "Representativeness of the study 2 sample"))`.


**Additional validity analyses of study 2**

The modeling for invariance testing has been gaining more relevance in sociological survey studies, mainly due to the interest in the validity of measurement scales in comparative studies in various social and cultural contexts [@davidov_measurement_2014]. In this section, we present the results of an analysis of invariance between groups, testing whether the proposed factorial structure for the meritocracy scale is applicable in a different dataset.

The invariance measurement procedure consists of a series of nested models in which restrictions are progressively incorporated into the parameters of the measurement model. The literature generally suggests that this modeling approach should consider four levels or types of progressive restriction [@milfont_testing_2010; @millsap_statistical_2011; @vandeschoot_checklist_2012]:

1. **Configural:** the model is estimated only indicating the factorial structure used in the CFA.

2. **Weak:** an equality restriction applied to the factor loadings in the different groups; that is, the loadings are forced to be identical in both measurements.

3. **Strong:** equality restrictions added to the intercepts of each indicator.

4. **Strict:** equality restrictions added to the error variances of each indicator.

**Data**

For testing the invariance, we compared the data described previously in Study 2 to a different dataset from an online survey carried out during the first half of 2020. The characteristics of this sample in terms of application and coverage are equivalent to those of the previous study. The final sample contains 1,242 cases, where 605 (48.71%) are women, and 637 (51.28%) are men. 48.84% are 45 or older, and 33.97% have tertiary education or higher.

**Variables**

The items of the meritocracy scale were identical to the original scale of Study 2 administrated in a randomized order (which corresponds to the application modality of Group 3 in Study 2, as shown in Figure \@ref(fig:appmod)).

**Results**

The first step for invariance testing is estimating the configural model, which serves as the baseline for further comparison and is expected to adequately meet the global fit criteria of a measurement model. Although the chi-square statistic is used as a global measure of fit, it is usually complemented with other indexes given its high sensitivity to sample size: the Comparative Fit Index (CFI), which should have a value greater than 0.95; the Root Mean Square Error Approximation (RMSEA), which must be lower than 0.06; and the Standardized Root Mean Square Residuals (SRMR) which must be less than 0.08 [@vandeschoot_checklist_2012]. Besides, the literature on measurement invariance suggests some complementary approaches for evaluating the fit, from which we will consider the incremental adjustment of the fit indexes [@cheung_evaluating_2002; @milfont_testing_2010; @dimitrov_testing_2010] and the ANOVA test for means comparison in nested models [@newsom_longitudinal_2015].

```{r invargroup, echo=FALSE}
  if (!require("pacman")) install.packages("pacman")
  #---Load packages and data -------------------------------------#
  pacman::p_load(dplyr,lavaan,semTools,knitr,kableExtra,stats,gtools)
  options(knitr.kable.NA = '')
  load(file = "input/data/proc/data_s3_inv.RData")
  pov01 <- data_s3_inv %>% dplyr::filter(dataset=="pvw01")
  fs01  <- data_s3_inv %>% dplyr::filter(dataset=="fsw02")

  #-----Meassurement model--------------------------------------#
  model01 <- '
  perc_merit  =~ perc_effort + perc_talent
  perc_nmerit =~ perc_wpart  + perc_netw
  pref_merit  =~ pref_effort + pref_talent
  pref_nmerit =~ pref_wpart  + pref_netw'

  #-----Invariance---------------------------------------------#
  inv01<- semTools::measurementInvariance(model=model01,data=data_s3_inv,group="dataset",estimator = "ML",strict=TRUE,quiet = T)

  conf  <- inv01$fit.configural
  weak  <- inv01$fit.loadings
  strong<- inv01$fit.intercepts
  strict<- inv01$fit.residuals

  tab01<- lavaan::anova(conf,weak,strong,strict,SB.classic=TRUE) %>%
    dplyr::as_tibble() %>%
    dplyr::select("Chisq","Df","chisq_diff"=`Chisq diff`,"df_diff"=`Df diff`,"pvalue"=`Pr(>Chisq)`) %>%
    dplyr::mutate(stars=gtools::stars.pval(pvalue),
           chisqt=paste0(round(Chisq,2)," (",Df,") "),
           decision=ifelse(pvalue>0.05,yes = "Accept",no = "Reject"),
           model=c("Configural","Weak","Strong","Strict"))

  fit.meas<- dplyr::bind_rows(lavaan::fitmeasures(inv01$fit.configural,output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),],
                              lavaan::fitmeasures(inv01$fit.loadings,  output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),],
                              lavaan::fitmeasures(inv01$fit.intercepts,output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),],
                              lavaan::fitmeasures(inv01$fit.residuals, output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),])

  # compute differences in chisq, df, cfi and rmsea (90%, lower.ci - upper.ci )
  fit.meas<- fit.meas %>%
    dplyr::mutate(diff.chi2 = chisq    - lag(chisq,default = dplyr::first(chisq)),
           diff.df   = df       - lag(df,   default = dplyr::first(df)),
           diff.cfi  = cfi      - lag(cfi,  default = dplyr::first(cfi)),
           diff.rmsea   = rmsea - lag(rmsea,default = dplyr::first(rmsea))) %>%
    round(3) %>%
    dplyr::mutate(rmsea.ci=paste0(rmsea," \n ", "(",rmsea.ci.lower,"-",rmsea.ci.upper,")"))

  tab.inv<- dplyr::bind_cols(tab01,fit.meas) %>%
    dplyr::select(model,chisqt,cfi,rmsea.ci,diff.chi2,diff.df,diff.cfi,diff.rmsea,stars,decision) %>%
    dplyr::mutate(diff.chi2=paste0(diff.chi2," (",diff.df,") ",stars)) %>%
    dplyr::select(model,chisqt,cfi,rmsea.ci,diff.chi2,diff.cfi,diff.rmsea,decision)

  #clean values
  tab.inv[tab.inv == c("0 (0) ")] <- NA
  tab.inv[tab.inv == c(0)] <- NA

  ### Check an alternative method
  configural        <- lavaan::cfa(model01, data=data_s3_inv, group = "dataset", estimator="ML")
  weak.invariance   <- lavaan::cfa(model01, data=data_s3_inv, group = "dataset",group.equal = "loadings", estimator="ML")
  strong.invariance <- lavaan::cfa(model01, data=data_s3_inv, group = "dataset",group.equal = c( "loadings", "intercepts"), estimator="ML")
  strict.invariance <- lavaan::cfa(model01, data=data_s3_inv, group = "dataset",group.equal = c( "loadings", "intercepts", "residuals"), estimator="ML")

  table_format = if(is_html_output()) {
    "html"
  } else if(is_latex_output()) {
    "latex"
  }

  col.nam <- c("Model","$\\chi^2 (\\text{df})$","CFI","RMSEA (90 CI)",
               "$\\Delta \\chi^2 (\\Delta \\text{df}$)","$\\Delta \\text{CFI}$","$\\Delta \\text{RMSEA}$","Decision")
  footnote <- paste0("N = ","; Group 1, n = ",conf@Data@nobs[[1]],"; Group 2, n = ",conf@Data@nobs[[2]], ", ***p < 0.001")

  knitr::kable(tab.inv, col.names = col.nam, align = "l",
        booktabs=TRUE,format = table_format,escape = FALSE,
        caption = "Multiple Group measurement invariance for Perceptions and Preferences for Meritocracy") %>%
    kableExtra::kable_styling(full_width = FALSE,
                              latex_options = "HOLD_position",
                              bootstrap_options=c("striped", "bordered"),
                              font_size = 10) %>%
    kableExtra::footnote(general = footnote, footnote_as_chunk = T)
```

Table \@ref(tab:invargroup) shows the results of the measurement invariance estimation. When attending to the traditional invariance test of $\Delta \chi^2 (\Delta \text{df})$, the results support the invariance at the strong level meaning that the fit of the factor model of the merit scale is equivalent across samples when constraining factor loadings and intercepts to being equal. Such result is considered in general as evidence of invariance [@fischer_are_2011], as strict forms of measurement invariance rarely hold [@vandeschoot_checklist_2012]. Still, the comparability of latent means requires strict invariance which in this case does not hold when considering just $\Delta \chi^2 (\Delta \text{df})$. Nevertheless, the criteria of $\Delta \text{CFI}$ used for comparing models is close to the rejection criteria of >.01, whereas the $\Delta \text{RMSEA}$ fulfills the requirements of being below the cut-off criteria as suggested by [@chen_sensitivity_2007]. Therefore, using this last standard, the level of strict invariance would hold for the meritocracy scale.

**Discusion** 

Based on the measurement invariance analysis for two datasets, we found evidence supporting the equivalence of the scale when applied in different samples. This gives a more robust ground when using this measure for comparing groups, for instance in country comparisons. Although the results are promising, still the analysis was performed in two samples in a single country (Chile) and it requires further examination with social surveys in other societies.


```{r tb-perpref1, eval=FALSE, include=FALSE}
 if (!require("pacman")) install.packages("pacman")
 load(file = "input/data/proc/data_s1.RData")
 pacman::p_load(dplyr,knitr,kableExtra)
 options(knitr.kable.NA = '')
 table_format = if(knitr::is_html_output()) { #conditional instructions for kable
   "html" #if html set "html" in format
 } else if(knitr::is_latex_output()) {
   "latex"#if latex set "latex" in format
 }

 # First order model for Appendix
 cfa_perpref1 <- '
 	  # latent variables
 	  percmerit =~ hwork + ambition
 	  percnmerit=~ wealthy + pareduc +race + gender +people + polcone
 	  prefmerit =~ welljob + hardjob
 	  prefnmerit=~ family + child
 	  '
 # Fit First order model for Appendix
 fit_perpref1 <- lavaan::cfa(cfa_perpref1, data = data_s1,
                             ordered = c("wealthy","pareduc","ambition","hwork",
                                         "people","polcone","race","gender",
                                         "respons","yeduc",
                                         "family","child",
                                         "welljob","hardjob"))
 # Labels of First order model for Appendix
 labs <- c(
   "Importance: hard work",
   "Importance: having ambition",
   "Importance: wealthy family",
   "Importance: educated parents",
   "Importance: race",
   "Importance: gender",
   "Importance: knowing people",
   "Importance: political connections",
   "Reasons for pay: well job",
   "Reasons for pay: hard job",
   "Reasons for pay: support family",
   "Reasons for pay: has children"
 )
 #Extract factor loadings
 tb.load<- data.frame(round(cbind(lavaan::inspect(fit_perpref1,
                                                         what="std")$lambda),
                            digits = 3))
 tb.load[tb.load==c(0.00)] <- NA #set to NA factor loadings of 0

 for (i in names(tb.load)) {
   tb.load[,i] <- sprintf(tb.load[,i], fmt = '%#.3f') #set values as character
 }
 tb.load[tb.load=="NA"] <- "" #set NA values to "" (empty space)
 #---extract fit measures-------#
 fm01<- data.frame(t(data.frame(lavaan::fitmeasures(fit_perpref1, output ="matrix")[c("chisq","df","cfi","tli","rmsea"),])));  row.names(fm01) ="percnmerit"

 #------chi2, df------#
 fm04<- round(rbind(fm01),3) #select and round to 4 digits
 fm04.1 <- fm04 %>% dplyr::select(chisq,df) #select chi2 and degrees of freedom
 fm04.1$chisq <- round(x = fm04.1$chisq,digits = 1) # round Chi2 to 1 digit
 fm04.1$df <- round(x = fm04.1$df,digits = 0) #round Df to 0 digits
 fm04.1$chi2df <- paste0(fm04.1$chisq,"(",fm04.1$df,")") #Paste chi2(df)
 fm04.1 <- dplyr::select(fm04.1,"chi2df") #select final column
 for (i in names(fm04.1)) {
   fm04.1[,i] <- as.character(fm04.1[,i]) # transform all to character
 }

 #------CFI, RMSEA------#
 fm04.2 <- fm04 %>% dplyr::select(cfi,tli,rmsea) # select CFI, TLI and RMSEA
 for (i in names(fm04.2)) {                      # transform all to character
   fm04.2[,i] <- sprintf(fm04.2[,i], fmt = '%#.3f')
 }

 fm.df      <- dplyr::bind_cols(fm04.1,fm04.2) # factor loading and labels
 fm.df$nobs <- c(lavaan::nobs(fit_perpref1))   # add number of observations
 fm.df <- data.frame(t(fm.df)); colnames(fm.df) <- c("percmerit") #transpose and set colnames

 #------ merge ------#
 tb.fm<- dplyr::bind_rows(tb.load,fm.df) #merge factor loadings and fit indices
 tb.fm<- tb.fm %>%
   dplyr::mutate(vars=c(labs,"$\\chi^2\\text{(df)}$","$\\text{CFI}$",
                        "$\\text{TLI}$","$\\text{RMSEA}$","$N$")) %>%
   dplyr::select(vars,everything()) #Change names of Fit meassures to latex symbols
 tb.perpref1 <- tb.fm #final matrix for Table

 # Table --------------------------------------------------------------------.
 tb.foot <- paste0("Standardized factor loadings using DWLS estimator ; CFI = Comparative fit index ;TLI = Tucker-Lewis index; RMSEA =  Root mean square error of approximation")
 tb.col <- c("","Meritocratic","Non-meritocratic",
             "Meritocratic","Non-meritocratic")
 tb.caption <- c(" Factor loadings and fit measures of the four first-order factor model in study 1")
 tb.issp<- kable(tb.perpref1,escape = FALSE,digits = 3,
                 align = "lcccc",
                 col.names = tb.col,
                 caption = tb.caption,
                 booktabs = T,
                 linesep = "",
                 format = table_format,
                 row.names=F) %>%
           kable_styling(latex_options = c("hold_position"),
                         bootstrap_options = c("striped", "bordered"),
                         position = "center",
                         font_size = 10) %>%
           add_header_above(header = c(" "=1,"Perception"= 2,"Preference"= 2)) %>%
           add_header_above(header = c(" "=1,"Factor loadings"= 4)) %>%
           row_spec(row = 12,hline_after = TRUE) %>%
           add_indent(c(13:17)) %>%
           footnote(general =tb.foot ,footnote_as_chunk = T,threeparttable = T);tb.issp
```

<!-- **Study 3** -->

```{r fcloads-inv, eval=FALSE, include=FALSE}
 if (!require("pacman")) install.packages("pacman")
 pacman::p_load(dplyr, knitr, kableExtra,lavaan)
 options(knitr.kable.NA = '')
 table_format = if(knitr::is_html_output()) { #conditional instructions for kable
   "html" #if html set "html" in format
 } else if(knitr::is_latex_output()) {
   "latex"#if latex set "latex" in format
 }
 table_format2 = if(knitr::is_html_output()) {
   T
 } else if(knitr::is_latex_output()) {
   F
 }
 # Note:
 # This CFA corresponds to the sample from the Factorial Survey Study
 load(file = "input/data/proc/data_s3_inv.RData") #load data study 3
 fs01  <- data_s3_inv %>% dplyr::filter(dataset=="fsw02") #subset sample

 # Set model
 model01 <- '
 perc_merit  =~ perc_effort + perc_talent
 perc_nmerit =~ perc_wpart  + perc_netw
 pref_merit  =~ pref_effort + pref_talent
 pref_nmerit =~ pref_wpart  + pref_netw'

 # Model fit
 fs1_o <- lavaan::cfa(model = model01,
              data = fs01,
              ordered = c("perc_effort","perc_talent",
                          "perc_wpart","perc_netw",
                          "pref_effort","pref_talent",
                          "pref_wpart","pref_netw"),std.lv=FALSE)

 # Extract information for table
 fm01<- data.frame(t(data.frame(lavaan::fitmeasures(fs1_o, output ="matrix")[c("chisq","df","cfi","tli","rmsea"),])));  row.names(fm01) ="M1.1"

 #------chi2, df------#
 fm04.1 <- fm01 %>% dplyr::select(chisq,df)
 fm04.1$chisq <- round(x = fm04.1$chisq,digits = 1)
 fm04.1$df <- round(x = fm04.1$df,digits = 0)
 fm04.1$chi2df <- paste0(fm04.1$chisq,"(",fm04.1$df,")")
 fm04.1 <- dplyr::select(fm04.1,"chi2df")

 #------CFI, RMSEA------#
 fm04.2 <- fm01 %>% dplyr::select(cfi,tli,rmsea)
 for (i in names(fm04.2)) {
   fm04.2[,i] <- sprintf(fm04.2[,i], fmt = '%#.3f')
 }

 #------ merge fit indices ------#
 fm.df      <- dplyr::bind_cols(fm04.1,fm04.2)
 fm.df$nobs <- c(lavaan::nobs(fs1_o))
 fm.df      <- data.frame(t(fm.df))

 #------ extract factor loadings ------#
 loads01<- data.frame(round(inspect(fs1_o,what="std")$lambda,digits = 3))
 loads01[loads01==c(0.00)] <- NA; names(loads01) <- c(paste0("M1.",1:4))

 for (i in names(loads01)) {
   loads01[,i] <- sprintf(loads01[,i], fmt = '%#.3f')
 }
 loads01[loads01=="NA"] <- ""

 #------ labels for table ------#
 labs <-c(
     "A. Perception Effort",
     "B. Perception Talent",
     "C. Perception Rich parents",
     "D. Perception Contacts",
     "E. Preferences Effort",
     "F. Preferences Talent",
     "G. Preferences Rich parents",
     "H. Preferences Contacts")

 #------ merge ------#
 tb.fm2<- dplyr::bind_rows(loads01,fm.df)
 tb.fm2<- tb.fm2 %>%
   dplyr::mutate(vars=c(labs,"$\\chi^2\\text{(df)}$","$\\text{CFI}$","$\\text{TLI}$","$\\text{RMSEA}$","$N$")) %>%
   dplyr::select(vars,everything())

 tb.col  <- c(" ",
              "Meritocratic","Non-meritocratic",
              "Meritocratic","Non-meritocratic")
 tb.caption <- "Factor loadings and fit measures for the second sample for study 3"
 tb.foot <- paste0("Standardized factor loadings using DWLS estimator ; CFI = Comparative fit index ;TLI = Tucker-Lewis index; RMSEA =  Root mean square error of approximation")
 tb.fm02<- knitr::kable(tb.fm2,escape = FALSE,
                        align = "lcccc",col.names = tb.col,
                        caption = tb.caption,
                        booktabs = T,linesep = "",
                        format = table_format,
                        row.names = F) %>%
           kableExtra::kable_styling(full_width = table_format2,
                         latex_options = c("hold_position"),
                         position = "center",
                         font_size = 10,
                         bootstrap_options = c("striped", "bordered")) %>%
           kableExtra::add_header_above(header = c(" "=1,"Perception"= 2,"Preference"= 2)) %>%
           kableExtra::add_header_above(header = c(" "=1,"Factor loadings"= 4)) %>%
           kableExtra::row_spec(row = 8,hline_after = TRUE) %>%
           kableExtra::add_indent(c(9:13)) %>%
           kableExtra::footnote(general =tb.foot ,footnote_as_chunk = T,threeparttable = T);tb.fm02
```

```{r fit-country-s2, eval=FALSE, include=FALSE}
if (!require("pacman")) install.packages("pacman")
  #---Load packages and data -------------------------------------#
  pacman::p_load(dplyr,lavaan,semTools,knitr,kableExtra,stats,gtools,haven)
  options(knitr.kable.NA = '')
  load(file = "input/data/proc/data_s1.RData")

# meassurement model: Second order
  cfa_perpref2 <- '
  	  # latent variables
  	  percmerit =~ hwork + ambition
  	  parents =~ wealthy + pareduc
  	  backgrd =~ race + gender
  	  networks=~ people + polcone
  	  percnmerit=~ parents + backgrd + networks
  	  prefmerit =~ welljob + hardjob
  	  prefnmerit=~ family + child
  	  '

  data_s1$country <- countrycode::countrycode(sourcevar = data_s1$v5,origin = "iso3n",destination = "country.name")
# estimar modelo por paises
df1<-data_s1 %>% select(country,wealthy:hardjob)
 
# sjmisc::frq(df1$country)
# 
# Argentina      <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Argentina",],ordered = T)
# Australia      <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Australia",],ordered = T)
# Austria        <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Austria",],ordered = T)
# Belgium        <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Belgium",],ordered = T)
# # Bulgaria       <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Bulgaria",],ordered = T)
# Chile          <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Chile",],ordered = T)
# China          <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="China",],ordered = T)
# Croatia        <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Croatia",],ordered = T)
# Cyprus         <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Cyprus",],ordered = T)
# Czechia        <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Czechia",],ordered = T)
# Denmark        <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Denmark",],ordered = T)
# Estonia        <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Estonia",],ordered = T)
# Finland        <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Finland",],ordered = T)
# France         <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="France",],ordered = T)
# Germany        <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Germany",],ordered = T)
# Hungary        <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Hungary",],ordered = T)
# # Iceland        <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Iceland",],ordered = T)
# Israel         <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Israel",],ordered = T)
# # Italy          <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Italy",],ordered = T)
# # Japan          <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Japan",],ordered = T)
# Latvia         <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Latvia",],ordered = T)
# # Lithuania      <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Lithuania",],ordered = T)
# NewZealand    <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="New Zealand",],ordered = T)
# Norway         <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Norway",],ordered = T)
# Philippines    <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Philippines",],ordered = T)
# Poland         <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Poland",],ordered = T)
# # Portugal       <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Portugal",],ordered = T)
# Russia         <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Russia",],ordered = T)
# Slovakia       <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Slovakia",],ordered = T)
# Slovenia       <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Slovenia",],ordered = T)
# SouthAfrica   <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="South Africa",],ordered = T)
# SouthKorea    <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="South Korea",],ordered = T)
# Spain          <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Spain",],ordered = T)
# # Sweden         <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Sweden",],ordered = T)
# Switzerland    <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Switzerland",],ordered = T)
# Taiwan         <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Taiwan",],ordered = T)
# Turkey         <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Turkey",],ordered = T)
# Ukraine        <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Ukraine",],ordered = T)
# UnitedKingdom <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="United Kingdom",],ordered = T)
# # UnitedStates  <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="United States",],ordered = T)
# # Venezuela      <- lavaan::cfa(cfa_perpref2,data = df1[df1$country=="Venezuela",],ordered = T)
# # 
# # 
# # 
# lavaan::fitmeasures(Argentina     )
# lavaan::fitmeasures(Australia     )
# lavaan::fitmeasures(Austria       )
# lavaan::fitmeasures(Belgium       )
# # lavaan::fitmeasures(# Bulgaria    )
# lavaan::fitmeasures(Chile         )
# lavaan::fitmeasures(China         )
# lavaan::fitmeasures(Croatia       )
# lavaan::fitmeasures(Cyprus        )
# lavaan::fitmeasures(Czechia       )
# lavaan::fitmeasures(Denmark       )
# lavaan::fitmeasures(Estonia       )
# lavaan::fitmeasures(Finland       )
# lavaan::fitmeasures(France        )
# lavaan::fitmeasures(Germany       )
# lavaan::fitmeasures(Hungary       )
# # lavaan::fitmeasures(# Iceland     )
# # lavaan::fitmeasures(Israel        )
# # lavaan::fitmeasures(Italy         )
# # lavaan::fitmeasures(# Japan       )
# lavaan::fitmeasures(Latvia        )
# # lavaan::fitmeasures(# Lithuania   )
# lavaan::fitmeasures(NewZealand    )
# lavaan::fitmeasures(Norway        )
# lavaan::fitmeasures(Philippines   )
# lavaan::fitmeasures(Poland        )
# # lavaan::fitmeasures(# Portugal    )
# lavaan::fitmeasures(Russia        )
# lavaan::fitmeasures(Slovakia      )
# lavaan::fitmeasures(Slovenia      )
# lavaan::fitmeasures(SouthAfrica   )
# lavaan::fitmeasures(SouthKorea    )
# lavaan::fitmeasures(Spain         )
# # lavaan::fitmeasures(# Sweden      )
# lavaan::fitmeasures(Switzerland   )
# lavaan::fitmeasures(Taiwan        )
# lavaan::fitmeasures(Turkey        )
# lavaan::fitmeasures(Ukraine       )
# lavaan::fitmeasures(UnitedKingdom )
# # lavaan::fitmeasures(UnitedStates)
# # lavaan::fitmeasures(Venezuela     )

df2<-data_s1 %>% select(country,wealthy:hardjob) %>% 
  filter(!country %in% c("Bulgaria","Iceland","Israel","Italy","Japan",
                         "Lithuania","Portugal","Sweden","United States","Venezuela"))

df_paises <- split(df2, df2$country)
results = lapply(df_paises, function(df2) lavaan::cfa(cfa_perpref2,data = df2,ordered = T))

#extraer fitmeasures por paises
results_list<- lapply(results, function(results) data.frame(t(lavaan::fitmeasures(results)[c("chisq","df","cfi","tli","rmsea")])))
#extraer nobs por paises
nobs_list <- lapply(results, function(results) data.frame(obs=t(lavaan::nobs(results))))
nobs_n <- data.table::rbindlist(nobs_list) %>% 
  mutate(country=names(nobs_list)) %>%
  select(country,everything())

  # extract fit indices from models and add to table
  sum_fit <- 
  data.table::rbindlist(results_list) %>% 
  mutate(country=names(results_list)) %>% 
  select(country,everything())
  # Customize object
  sum_fit$nobs <- nobs_n$obs
  sum_fit <- dplyr::select(sum_fit,country,"chisq","df", nobs,"cfi","tli","rmsea")
  sum_fit <- sum_fit %>% dplyr::arrange(chisq)
  colnames <- c("País","$\\chi^2$","gl","$N$","CFI","TLI","RMSEA")
  # Create table
  tab_cfa_count_1d <-
    kable(
      sum_fit,
      # format=table_format,
      digits = 3,
      booktabs = T,
      col.names = colnames,
      caption = "Summary of country-specific fit for the ISSP",
      escape = FALSE
    ) %>% 
    kable_styling(full_width = F,
                  font_size = 10,
                  latex_options = "HOLD_position",
                  bootstrap_options=c("striped", "bordered"))
  tab_cfa_count_1d
```


```{r invariance-s2, eval=FALSE, include=FALSE}
df2<-data_s1 %>% select(country,wealthy:hardjob) %>% 
  filter(!country %in% c("Bulgaria","Iceland","Israel","Italy","Japan",
                         "Lithuania","Portugal","Sweden","United States","Venezuela","Finland"))

  inv01 <- semTools::measurementInvariance(model=cfa_perpref2,
                                           data=df2,
                                           group="country",estimator = "ML",strict=TRUE,quiet = T)
  
  var_or <- c("hwork","ambition","wealthy", "pareduc","race",
              "gender","people","polcone","welljob" ,"hardjob","family","child") 
  
  inv02 <- semTools::measurementInvarianceCat(model=cfa_perpref2,
                                              data=df2,
                                           group="country",estimator = "DWLS",
                                           strict=TRUE,quiet = T,ordered=var_or)

conf  <- inv01$fit.configural
  weak  <- inv01$fit.loadings
  strong<- inv01$fit.intercepts
  strict<- inv01$fit.residuals

  ### Check an alternative method
  configural        <- lavaan::cfa(cfa_perpref2, data=df2, group = "country", estimator="ML")
  weak.invariance   <- lavaan::cfa(cfa_perpref2, data=df2, group = "country",group.equal = "loadings", estimator="ML")
  strong.invariance <- lavaan::cfa(cfa_perpref2, data=df2, group = "country",group.equal = c( "loadings", "intercepts"), estimator="ML")
  strict.invariance <- lavaan::cfa(cfa_perpref2, data=df2, group = "country",group.equal = c( "loadings", "intercepts", "residuals"), estimator="ML")
  
  
  
  tab01<- lavaan::anova(conf,weak,strong,strict,SB.classic=TRUE) %>%
    dplyr::as_tibble() %>%
    dplyr::select("Chisq","Df","chisq_diff"=`Chisq diff`,"df_diff"=`Df diff`,"pvalue"=`Pr(>Chisq)`) %>%
    dplyr::mutate(stars=gtools::stars.pval(pvalue),
           chisqt=paste0(round(Chisq,2)," (",Df,") "),
           decision=ifelse(pvalue>0.05,yes = "Accept",no = "Reject"),
           model=c("Configural","Weak","Strong","Strict"))

  fit.meas<- dplyr::bind_rows(lavaan::fitmeasures(inv01$fit.configural,output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),],
                              lavaan::fitmeasures(inv01$fit.loadings,  output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),],
                              lavaan::fitmeasures(inv01$fit.intercepts,output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),],
                              lavaan::fitmeasures(inv01$fit.residuals, output ="matrix")[c("chisq","df","cfi","rmsea","rmsea.ci.lower","rmsea.ci.upper"),])

  # compute differences in chisq, df, cfi and rmsea (90%, lower.ci - upper.ci )
  fit.meas<- fit.meas %>%
    dplyr::mutate(diff.chi2 = chisq    - lag(chisq,default = dplyr::first(chisq)),
           diff.df   = df       - lag(df,   default = dplyr::first(df)),
           diff.cfi  = cfi      - lag(cfi,  default = dplyr::first(cfi)),
           diff.rmsea   = rmsea - lag(rmsea,default = dplyr::first(rmsea))) %>%
    round(3) %>%
    dplyr::mutate(rmsea.ci=paste0(rmsea," \n ", "(",rmsea.ci.lower,"-",rmsea.ci.upper,")"))

  tab.inv<- dplyr::bind_cols(tab01,fit.meas) %>%
    dplyr::select(model,chisqt,cfi,rmsea.ci,diff.chi2,diff.df,diff.cfi,diff.rmsea,stars,decision) %>%
    dplyr::mutate(diff.chi2=paste0(diff.chi2," (",diff.df,") ",stars)) %>%
    dplyr::select(model,chisqt,cfi,rmsea.ci,diff.chi2,diff.cfi,diff.rmsea,decision)

  #clean values
  tab.inv[tab.inv == c("0 (0) ")] <- NA
  tab.inv[tab.inv == c(0)] <- NA

  ### Check an alternative method
  configural        <- lavaan::cfa(model01, data=data_s3_inv, group = "dataset", estimator="ML")
  weak.invariance   <- lavaan::cfa(model01, data=data_s3_inv, group = "dataset",group.equal = "loadings", estimator="ML")
  strong.invariance <- lavaan::cfa(model01, data=data_s3_inv, group = "dataset",group.equal = c( "loadings", "intercepts"), estimator="ML")
  strict.invariance <- lavaan::cfa(model01, data=data_s3_inv, group = "dataset",group.equal = c( "loadings", "intercepts", "residuals"), estimator="ML")

  table_format = if(is_html_output()) {
    "html"
  } else if(is_latex_output()) {
    "latex"
  }

  col.nam <- c("Model","$\\chi^2 (\\text{df})$","CFI","RMSEA (90 CI)",
               "$\\Delta \\chi^2 (\\Delta \\text{df}$)","$\\Delta \\text{CFI}$","$\\Delta \\text{RMSEA}$","Decision")
  footnote <- paste0("N = ","; Group 1, n = ",conf@Data@nobs[[1]],"; Group 2, n = ",conf@Data@nobs[[2]], ", ***p < 0.001")

  knitr::kable(tab.inv, col.names = col.nam, align = "l",
        booktabs=TRUE,format = table_format,escape = FALSE,
        caption = "Multiple Group measurement invariance for Perceptions and Preferences for Meritocracy") %>%
    kableExtra::kable_styling(full_width = FALSE,
                              latex_options = "HOLD_position",
                              bootstrap_options=c("striped", "bordered"),
                              font_size = 10) %>%
    kableExtra::footnote(general = footnote, footnote_as_chunk = T)
```


